{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas matplotlib\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_intervals = [32, 64, 128]\n",
    "ingest_rates = [10_000_000, 8_000_000, 6_000_000, 4_000_000, 2_000_000] # 0 to indicate no limit\n",
    "path_to_graph, timestamp_position = \"~/wikipedia-growth.txt\", 2\n",
    "path_to_project = \"~/projects/lollipop\"\n",
    "path_to_go = shutil.which(\"go\")\n",
    "threads = 10 # 0 to use nproc\n",
    "\n",
    "path_to_graph = Path(path_to_graph).expanduser()\n",
    "path_to_project = Path(path_to_project).expanduser()\n",
    "assert(path_to_graph.exists())\n",
    "assert(path_to_project.exists())\n",
    "assert(path_to_go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_directory():\n",
    "    path_to_results = path_to_project / \"results\" / f\"2023-sc-poster\"\n",
    "    path_to_results.mkdir(exist_ok=True)\n",
    "    return path_to_results\n",
    "\n",
    "(path_to_project / \"results\").mkdir(exist_ok=True)\n",
    "results_dir = create_results_directory() # or replace with existing result folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Algorithm:\n",
    "    def __init__(self, name: str, graph: Path, results_dir: Path, timeseries_output: Path, timestamp_position: int, convert_to_undirected: bool = False, threads: int = 0) -> None:\n",
    "        self.name = name\n",
    "        self.code_path = path_to_project / \"cmd\" / f\"lp-{name}\"\n",
    "        self.results_dir = results_dir\n",
    "        self.convert_to_undirected = convert_to_undirected\n",
    "        self.graph = graph\n",
    "        self.timestamp_position = timestamp_position\n",
    "        self.threads = threads\n",
    "        self.timeseries_output = timeseries_output\n",
    "        assert(self.graph.exists())\n",
    "        assert(self.results_dir.exists())\n",
    "        assert(self.code_path.exists())\n",
    "        assert(self.timeseries_output.parent.exists())\n",
    "\n",
    "    def run_timeseries(self, timeseries_interval: int, ingest_rate: int = 0, suffix: str = \"\", no_skip: bool = False) -> Path:\n",
    "        path_timeseries = self.results_dir / f\"timeseries-{self.name}-{timeseries_interval}-{ingest_rate}-{self.threads}{suffix}.csv\"\n",
    "        # path_timeseries = self.results_dir / f\"timeseries-{self.name}-{timeseries_interval}-{ingest_rate}.csv\"\n",
    "        if (not no_skip) and path_timeseries.exists():\n",
    "            print(f\"Skipping as result exists: {path_timeseries}\")\n",
    "            return path_timeseries\n",
    "\n",
    "        cmd = [path_to_go, \"run\", self.code_path, \"-c\", \"-tquery\", f\"-pt={self.timestamp_position}\", f\"-g={self.graph}\", f\"-dt={timeseries_interval}\"]\n",
    "        if ingest_rate:\n",
    "            cmd.append(f\"-dr={ingest_rate}\")\n",
    "        if self.convert_to_undirected:\n",
    "            cmd.append(\"-u\")\n",
    "        if self.threads:\n",
    "            cmd.append(f\"-t={self.threads}\")\n",
    "        \n",
    "        print(f\"Command: {cmd}\")\n",
    "        self.timeseries_output.unlink(missing_ok=True)\n",
    "        process = subprocess.Popen(cmd, cwd=path_to_project)\n",
    "        process.wait()\n",
    "\n",
    "        assert(self.timeseries_output.exists())\n",
    "        return self.timeseries_output.rename(path_timeseries)\n",
    "    \n",
    "pagerank = Algorithm(name=\"pagerank\", graph=path_to_graph, results_dir=results_dir, \n",
    "                     timeseries_output=path_to_project / \"results\" / \"timeseries.csv\", \n",
    "                     timestamp_position=timestamp_position, \n",
    "                     convert_to_undirected=False, threads=threads)\n",
    "\n",
    "colouring = Algorithm(name=\"colouring\", graph=path_to_graph, results_dir=results_dir, \n",
    "                     timeseries_output=path_to_project / \"results\" / \"colouring-timeseries.csv\", \n",
    "                     timestamp_position=timestamp_position, \n",
    "                     convert_to_undirected=True, threads=threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, results_dir: Path, algorithm: Algorithm) -> None:\n",
    "        self.algorithm = algorithm\n",
    "        self.results_dir = results_dir\n",
    "        self.path_results_db = results_dir / \"timeseries-db.csv\"\n",
    "        if self.path_results_db.exists():\n",
    "            self.results_db = pd.read_csv(self.path_results_db)\n",
    "        else:\n",
    "            self.results_db = pd.DataFrame(columns=[\"Algorithm\", \"Query Interval\", \"Number of Queries\", \"Ingest Rate\", \"Average Latency\", \"Threads\", \"Timeseries Path\"])\n",
    "            self.results_db.to_csv(self.path_results_db, index=False)\n",
    "        assert(self.results_dir.exists())\n",
    "\n",
    "    def run(self, timeseries_intervals: list[int], ingest_rates: list[int], repeat: int=1) -> Path:\n",
    "        for interval in timeseries_intervals:\n",
    "            for rate in ingest_rates:\n",
    "                for r in range(repeat):\n",
    "                    timeseries = self.algorithm.run_timeseries(timeseries_interval=interval, ingest_rate=rate, suffix=f\"-{r}\")\n",
    "                    df_timeseries = pd.read_csv(timeseries)\n",
    "                    average_latency = df_timeseries.loc[:, 'qLatencyMS'].mean()\n",
    "                    self.results_db.loc[len(self.results_db)] = {\n",
    "                        \"Algorithm\": self.algorithm.name,\n",
    "                        \"Query Interval\": interval,\n",
    "                        \"Number of Queries\": df_timeseries.shape[0],\n",
    "                        \"Ingest Rate\": rate,\n",
    "                        \"Average Latency\": average_latency,\n",
    "                        \"Threads\": self.algorithm.threads,\n",
    "                        \"Timeseries Path\": timeseries\n",
    "                    }\n",
    "                    self.results_db.to_csv(self.path_results_db, index=False)\n",
    "        return self.path_results_db\n",
    "\n",
    "    def load_results(self) -> pd.DataFrame:\n",
    "        return pd.read_csv(self.path_results_db)\n",
    "\n",
    "pagerank_experiment = Experiment(results_dir, pagerank)\n",
    "colouring_experiment = Experiment(results_dir, colouring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pagerank_experiment.run(timeseries_intervals, ingest_rates)\n",
    "# pagerank_results = pagerank_experiment.load_results()\n",
    "# pagerank_results\n",
    "colouring_experiment.run(timeseries_intervals, ingest_rates, repeat=5)\n",
    "colouring_results = colouring_experiment.load_results()\n",
    "colouring_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_latency(timeseries_paths: list[str]) -> pd.DataFrame:\n",
    "    assert(timeseries_paths.shape[0] > 0)\n",
    "    output_df = pd.read_csv(timeseries_paths.iloc[0])\n",
    "    output_df = output_df[['ts', 'qLatencyMS']].copy()\n",
    "\n",
    "    for path in timeseries_paths[1:]:\n",
    "        df = pd.read_csv(path)\n",
    "        assert((df['ts'] == output_df['ts']).all())\n",
    "        output_df['qLatencyMS'] = output_df['qLatencyMS'].add(df['qLatencyMS'], fill_value=0)\n",
    "    \n",
    "    output_df['ts'] = pd.to_datetime(output_df['ts'])\n",
    "    output_df['qLatencyMS'] = output_df['qLatencyMS'] / len(timeseries_paths)\n",
    "    return output_df\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "def plot(timeseries_results, y_max, x_min):\n",
    "\n",
    "    timeseries_path = timeseries_results.query(f'`Query Interval` == {min(timeseries_intervals)}').iloc[0][\"Timeseries Path\"]\n",
    "    df_timeseries = pd.read_csv(timeseries_path)\n",
    "    ts, e = pd.to_datetime(df_timeseries['ts']), df_timeseries['EC']\n",
    "    min_ts, max_ts, max_e = min(ts), max(ts), max(e)\n",
    "    print(f\"min(ts)={min_ts} max(ts)={max_ts} e={e}\")\n",
    "    \n",
    "    fig, axs = plt.subplots(len(timeseries_intervals), len(ingest_rates), sharex=True, figsize=(6, 4))\n",
    "\n",
    "    for interval, axs_y in zip(timeseries_intervals, axs):\n",
    "        for rate, ax in zip(ingest_rates, axs_y):\n",
    "            ax = ax.twinx()\n",
    "            if rate != ingest_rates[-1]:\n",
    "                ax.set_yticks([])\n",
    "            ax.set_zorder(1)\n",
    "            ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "            ax.margins(x=0)\n",
    "            ax.set_ylim([0, 1])\n",
    "            ax.fill_between(ts, e / max_e, alpha=0.2, facecolor=\"green\", edgecolor=None, label=f\"% of edges added\")\n",
    "\n",
    "    for interval, axs_y in zip(timeseries_intervals, axs):\n",
    "        for rate, ax in zip(ingest_rates, axs_y):\n",
    "            timeseries_filtered = timeseries_results.query(f'`Query Interval` == {interval} and `Ingest Rate` == {rate} and `Threads` == {threads}')\n",
    "\n",
    "            df_averaged = get_average_latency(timeseries_filtered[\"Timeseries Path\"])\n",
    "            x, y1 = df_averaged['ts'], df_averaged['qLatencyMS']\n",
    "\n",
    "            ax.patch.set_visible(False)\n",
    "            ax.margins(x=0)\n",
    "            ax.set(xlim=[x_min, max_ts], ylim=[0,y_max], zorder=2, xticks=[])\n",
    "            ax.plot(x, y1, marker = '.', markersize = 5, color=\"chocolate\", label=\"Latency\")\n",
    "            ax.fill_between(x, y1, alpha=0.2, facecolor=\"red\", edgecolor=None)\n",
    "\n",
    "            if rate != ingest_rates[0]:\n",
    "                ax.set_yticks([])\n",
    "\n",
    "            if rate == ingest_rates[0] or (rate == ingest_rates[1] and interval <= 32):\n",
    "                ax = ax.twinx().twiny() # don't share any axes\n",
    "                ax.set(xlim=[0,1], ylim=[0,1], zorder=0, xticks=[], yticks=[])\n",
    "                ax.scatter(0.2, 0.85, marker=\"x\", color=\"brown\", s=100, label=\"Target rate not achieved\")\n",
    "\n",
    "    for interval, ax in zip(timeseries_intervals, axs[:, 0]):\n",
    "        ax.set_ylabel(f\"{interval} days\", labelpad=7)\n",
    "    for rate, ax in zip(ingest_rates, axs[-1]):\n",
    "        ax.set_xlabel(f\"{rate/1e6}m e/s\", labelpad=7)\n",
    "    \n",
    "    # Legend\n",
    "    handles, labels = [sum(x, []) for x in zip(*[ax.get_legend_handles_labels() for ax in fig.axes])]\n",
    "    handles_labels = dict(zip(labels, handles))\n",
    "    fig.legend(handles_labels.values(), handles_labels.keys(), framealpha=0.9)\n",
    "    \n",
    "    fig.tight_layout(pad=0.5)\n",
    "    return fig\n",
    "\n",
    "fig = plot(colouring_results, 1000, pd.to_datetime(\"2005-03-15\"))\n",
    "fig.savefig(results_dir / \"rate-limiting.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
