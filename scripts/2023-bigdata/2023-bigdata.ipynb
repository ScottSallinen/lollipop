{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "This notebook contains the scripts to run all experiments and generate all figures in the paper.\n",
    "Please follow the these step:\n",
    "1. Run `pipenv install` to install the python dependencies specified in `Pipfile` and `Pipfile.lock`.\n",
    "2. Ensure `go version` is `1.20.6`.\n",
    "3. Update the values of the variables in the following cell.\n",
    "4. Run all cells in this notebook with the python environment created in Step 1.\n",
    "5. The results will be saved in the directory `results/2023-bigdata/output/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "project_path = \"~/projects/lollipop\" # root of the repository\n",
    "path_hive_comments = \"~/hive-comments.txt\"\n",
    "path_wikipedia_growth = \"~/wikipedia-growth.txt\"\n",
    "path_eth_transfers = \"~/eth-transfers-t200m.txt.p\"\n",
    "path_flickr = \"~/flickr-growth.txt\"\n",
    "path_roadnet = \"~/roadNet-CA.txt.shuffled\" # shuffled with random edge weights added # ignore this for now\n",
    "\n",
    "# settings for i5-12600K\n",
    "threads = [2, 4, 6] # ignore this for now\n",
    "default_thread = 8\n",
    "cpu_affinity_masks = {2: range(4), 4: range(8), 6: range(12)} # ignore this for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re\n",
    "import time\n",
    "import statistics\n",
    "import os, signal\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hive_comments_pagerank = [5880, 38806, 85033, 6379, 499, 43668, 27029, 3943, 396, 383716]\n",
    "hive_comments_transpose_pagerank = [38806, 5880, 613937, 51025, 328593, 554966, 543979, 392586, 383716, 448577]\n",
    "eth_transfers_pagerank = [3979551, 109769957, 73084091, 514110, 359557, 60806159, 13873739, 21585619, 28827290, 33082862]\n",
    "eth_transfers_transpose_pagerank = [109421, 7724, 101776590, 3979551, 335165, 109769957, 1948, 87368785, 4875253, 13001]\n",
    "wikipedia_pagerank = [73, 259, 9479, 6276, 1710, 864, 2169, 110, 10312, 69]\n",
    "wikipedia_transpose_pagerank = [205298, 437592, 117461, 1184369, 1121429, 1550595, 205299, 205305, 1255505, 178961]\n",
    "flickr_pagerank = [377, 657, 3160, 390, 786, 1467, 23, 994, 61, 376]\n",
    "flickr_transpose_pagerank = [784, 27327, 3160, 3169, 6965, 67, 185034, 798, 110435, 657]\n",
    "roadnet_pagerank = [225438, 287362, 562818, 241926, 521168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go = Path(shutil.which(\"go\"))\n",
    "project_path = Path(project_path).expanduser()\n",
    "path_hive_comments = Path(path_hive_comments).expanduser()\n",
    "path_wikipedia_growth = Path(path_wikipedia_growth).expanduser()\n",
    "path_eth_transfers = Path(path_eth_transfers).expanduser()\n",
    "path_flickr = Path(path_flickr).expanduser()\n",
    "path_roadnet = Path(path_roadnet).expanduser()\n",
    "assert go.exists()\n",
    "assert project_path.exists()\n",
    "assert path_hive_comments.exists()\n",
    "assert path_wikipedia_growth.exists()\n",
    "assert path_eth_transfers.exists()\n",
    "assert path_flickr.exists()\n",
    "assert path_roadnet.exists()\n",
    "\n",
    "# TODO: check hashes of graph files\n",
    "\n",
    "push_relabel_code = project_path / \"cmd\" / f\"lp-push-relabel\"\n",
    "assert push_relabel_code.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_directory(top_dir: Path):\n",
    "    results_dir = top_dir / f\"2023-bigdata\"\n",
    "    log_dir = results_dir / \"log\"\n",
    "    ts_dir = results_dir / \"ts\"\n",
    "    output_dir = results_dir / \"output\"\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    log_dir.mkdir(exist_ok=True)\n",
    "    ts_dir.mkdir(exist_ok=True)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    return results_dir, output_dir, log_dir, ts_dir\n",
    "\n",
    "(project_path / \"results\").mkdir(exist_ok=True)\n",
    "results_dir, output_dir, log_dir, ts_dir = create_results_directory(project_path / \"results\")\n",
    "path_timeseries_output = project_path / \"results\" / \"push-relabel-timeseries.csv\"\n",
    "path_timeseries_flow_output = project_path / \"results\" / \"push-relabel-timeseries-flow.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(kw_only=True)\n",
    "class Graph:\n",
    "    name: str\n",
    "    path: Path\n",
    "    pw: int\n",
    "    pt: int\n",
    "    undirected: bool = False\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class MaxFlowTestCase:\n",
    "    graph: Graph\n",
    "    st_index: int\n",
    "    s: int\n",
    "    t: int\n",
    "\n",
    "    def get_name(self) -> str:\n",
    "        return f\"{self.graph.name}-{self.st_index}\"\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class BasicTestCase(MaxFlowTestCase):\n",
    "    threads: int = default_thread\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class StaticTestCase(BasicTestCase):\n",
    "    pass\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class DynamicTestCase(BasicTestCase):\n",
    "    target_ingest_rate: int = 0\n",
    "    delete_window: int = 0\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class TimeseriesTestCase(DynamicTestCase):\n",
    "    interval_time: int = None\n",
    "    interval_edge: int = None\n",
    "    track_progress: bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        assert (self.interval_time and not self.interval_edge) or \\\n",
    "            (not self.interval_time and self.interval_edge), \\\n",
    "            \"Exactly one of dt or de must set\"\n",
    "\n",
    "graph_hive_comments = Graph(name=\"Hive-comments\", path=path_hive_comments, pw=None, pt=1)\n",
    "graph_wikipedia_growth = Graph(name=\"Wikipedia-growth\", path=path_wikipedia_growth, pw=None, pt=2)\n",
    "graph_eth_transfers = Graph(name=\"Eth-transfers-t200m\", path=path_eth_transfers, pw=1, pt=None) # TODO: fix pw and pt\n",
    "graph_flickr_growth = Graph(name=\"Flickr-growth\", path=path_flickr, pw=None, pt=2)\n",
    "graph_roadnet = Graph(name=\"RoadNet-CA\", path=path_roadnet, pw=1, pt=None)\n",
    "\n",
    "tc_hive_comments = [MaxFlowTestCase(graph=graph_hive_comments, st_index=i, s=s, t=t) for i, (t, s) in enumerate(zip(hive_comments_pagerank, hive_comments_transpose_pagerank))]\n",
    "tc_wikipedia_growth = [MaxFlowTestCase(graph=graph_wikipedia_growth, st_index=i, s=s, t=t) for i, (t, s) in enumerate(zip(wikipedia_pagerank, wikipedia_transpose_pagerank))]\n",
    "tc_eth_transfers = [MaxFlowTestCase(graph=graph_eth_transfers, st_index=i, s=s, t=t) for i, (t, s) in enumerate(zip(eth_transfers_pagerank, eth_transfers_transpose_pagerank))]\n",
    "tc_flickr_growth = [MaxFlowTestCase(graph=graph_flickr_growth, st_index=i, s=s, t=t) for i, (t, s) in enumerate(zip(flickr_pagerank, flickr_transpose_pagerank))]\n",
    "tc_roadnet = [MaxFlowTestCase(graph=graph_roadnet, st_index=0, s=roadnet_pagerank[0], t=roadnet_pagerank[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StaticResult:\n",
    "    test_case: StaticTestCase\n",
    "    time_alg: int\n",
    "    time_general: int\n",
    "\n",
    "@dataclass\n",
    "class TimeseriesResult:\n",
    "    test_case: TimeseriesTestCase\n",
    "\n",
    "    ingest_rate_actual: int\n",
    "    time_termination: int\n",
    "    latency_mean: int\n",
    "    query_count: int\n",
    "    timeseries: pd.DataFrame\n",
    "    timeseries_flow: pd.DataFrame\n",
    "    progress: pd.DataFrame\n",
    "\n",
    "def get_static_result(tc: StaticTestCase, path_log: Path) -> StaticResult:\n",
    "    assert isinstance(tc, StaticTestCase)\n",
    "\n",
    "    log = path_log.read_text()\n",
    "\n",
    "    time_alg = re.findall(r\"Termination: ([0-9]+)\", log)\n",
    "    assert len(time_alg) == 1 \n",
    "    time_alg = int(time_alg[0])\n",
    "\n",
    "    time_general = re.findall(r\"Total including streaming: ([0-9]+)\", log)\n",
    "    assert len(time_general) == 1 \n",
    "    time_general = int(time_general[0])\n",
    "\n",
    "    max_flow = re.findall(r\"Maximum flow is ([0-9]+)\", log)\n",
    "    assert len(max_flow) == 1 \n",
    "    max_flow = int(max_flow[0])\n",
    "    \n",
    "    return StaticResult(test_case=tc, time_alg=time_alg, time_general=time_general)\n",
    "\n",
    "def get_ts_result(tc: TimeseriesTestCase, path_log: Path, path_timeseries: Path, path_timeseries_flow: Path) -> TimeseriesResult:\n",
    "    assert isinstance(tc, TimeseriesTestCase)\n",
    "\n",
    "    log = path_log.read_text()\n",
    "\n",
    "    time_termination = re.findall(r\"Termination: ([0-9]+)\", log)\n",
    "    assert len(time_termination) == 1 \n",
    "    time_termination = int(time_termination[0])\n",
    "\n",
    "    ingest_rate_actual = re.findall(r\"TotalRate ([0-9]+)\", log)\n",
    "    assert len(ingest_rate_actual) >= 1 \n",
    "    ingest_rate_actual = int(ingest_rate_actual[-1])\n",
    "\n",
    "    assert path_timeseries.exists()\n",
    "    timeseries = pd.read_csv(path_timeseries)\n",
    "\n",
    "    latency_mean = timeseries.loc[:, 'Latency'].mean()\n",
    "    query_count = timeseries.shape[0]\n",
    "\n",
    "    timeseries_flow = None\n",
    "    if path_timeseries_flow:\n",
    "        timeseries_flow = pd.read_csv(path_timeseries_flow)\n",
    "\n",
    "    progress = None\n",
    "    if tc.track_progress:\n",
    "        progress = []\n",
    "        progress_matches = re.findall(r\"Current Progress, Time: ([0-9]+), SourceSent: ([0-9]+), SinkReceived: ([0-9]+)\", log)\n",
    "        progress_matches = [(int(a), \"flow\", int(b), int(c), None) for a, b, c in progress_matches]\n",
    "        query_start_matches = re.findall(r\"ExecuteQuery start, Time: ([0-9]+), entry: ([0-9]+)\", log)\n",
    "        query_start_matches = [(int(a), \"query-triggered\", None, None, int(b)) for a, b in query_start_matches]\n",
    "        query_end_matches = re.findall(r\"ExecuteQuery end, Time: ([0-9]+), entry: ([0-9]+)\", log)\n",
    "        query_end_matches = [(int(a), \"query-done\", None, None, int(b)) for a, b in query_end_matches]\n",
    "\n",
    "        progress = pd.DataFrame(progress_matches + query_start_matches + query_end_matches, columns=[\"time\", \"type\", \"source-sent\", \"sink-received\", \"entry\"])\n",
    "        progress.sort_values(\"time\")\n",
    "\n",
    "\n",
    "    return TimeseriesResult(test_case=tc, ingest_rate_actual=ingest_rate_actual, \n",
    "                            time_termination=time_termination, latency_mean=latency_mean, \n",
    "                            query_count=query_count, \n",
    "                            timeseries=timeseries, timeseries_flow=timeseries_flow,\n",
    "                            progress=progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(tc: BasicTestCase, repeat_index: int = 0, correctness: bool = True, add_flags: list[str] = [], suffix: str = \"\", cpu_affinity: bool = False, no_skip: bool = False) -> Path:\n",
    "    assert isinstance(tc, BasicTestCase)\n",
    "\n",
    "    # compile command and log filename\n",
    "    cmd = [go, \"run\", push_relabel_code, \"-nc\", f\"-t={tc.threads}\", f\"-g={tc.graph.path}\"]\n",
    "    log_filename = f\"push-relabel-t={tc.threads}-g={tc.graph.path.name}\"\n",
    "    if tc.graph.undirected:\n",
    "        cmd.append(\"-u\")\n",
    "        log_filename += \"-u\"\n",
    "    if tc.graph.pw:\n",
    "        cmd += [f\"-pw={tc.graph.pw}\"]\n",
    "        log_filename += f\"-pw={tc.graph.pw}\"\n",
    "    if tc.graph.pt:\n",
    "        cmd += [f\"-pt={tc.graph.pt}\"]\n",
    "        log_filename += f\"-pt={tc.graph.pt}\"\n",
    "\n",
    "    cmd += [f\"-S={tc.s}\", f\"-T={tc.t}\"]\n",
    "    log_filename += f\"-S={tc.s}-T={tc.t}\"\n",
    "\n",
    "    if correctness:\n",
    "        cmd += [\"-c\"]\n",
    "        log_filename += \"-c\"\n",
    "    if cpu_affinity:\n",
    "        log_filename += \"-cpuaff\"\n",
    "\n",
    "    cmd += add_flags\n",
    "    log_filename += f\"{suffix}.{repeat_index}.log\"\n",
    "\n",
    "    # Run command\n",
    "    log_path = log_dir / log_filename\n",
    "    print(f\"Command: {cmd}\")\n",
    "    print(f\"Log path: {log_path}\")\n",
    "\n",
    "    if (not no_skip) and log_path.exists():\n",
    "        print(f\"Skipped as the log file exists\")\n",
    "        return log_path\n",
    "\n",
    "    path_log_temp = log_dir / f\"_running-{log_filename}\"\n",
    "    with open(path_log_temp, \"w+t\") as log_file:\n",
    "        def preexec_fn():\n",
    "            os.setpgrp()\n",
    "            if cpu_affinity:\n",
    "                os.sched_setaffinity(os.getpid(), cpu_affinity_masks[tc.threads])\n",
    "        process = sp.Popen(cmd, cwd=project_path, stdout=log_file, stderr=sp.STDOUT, preexec_fn=preexec_fn)\n",
    "        time.sleep(0.5)\n",
    "        if cpu_affinity:\n",
    "            assert set(cpu_affinity_masks[tc.threads]) == set(os.sched_getaffinity(process.pid)), \\\n",
    "                f\"{cpu_affinity_masks[tc.threads]} != {os.sched_getaffinity(process.pid)}\"\n",
    "        try:\n",
    "            returncode = process.wait()\n",
    "        except KeyboardInterrupt as ki:\n",
    "            os.killpg(os.getpgid(process.pid), signal.SIGTERM)\n",
    "            process.kill()\n",
    "            raise ki\n",
    "        if returncode != 0:\n",
    "            assert False, f\"Return code is none-zero: {returncode}\"\n",
    "    \n",
    "    path_log_temp.rename(log_path)\n",
    "    print(f\"Log saved\")\n",
    "    \n",
    "    return log_path\n",
    "\n",
    "def run_algorithm_static(tc: StaticTestCase, **kwargs) -> StaticResult:\n",
    "    assert isinstance(tc, StaticTestCase)\n",
    "\n",
    "    path_log = run_algorithm(tc=tc, **kwargs)\n",
    "    return get_static_result(tc=tc, path_log=path_log)\n",
    "\n",
    "def run_algorithm_ts(tc: TimeseriesTestCase, repeat_index: int = 0, stability: bool = False, no_skip: bool = False, **kwargs) -> TimeseriesResult:\n",
    "    assert isinstance(tc, TimeseriesTestCase)\n",
    "    assert (tc.interval_time and not tc.interval_edge) or (not tc.interval_time and tc.interval_edge), \"Exactly one of dt or de must set\"\n",
    "    assert not tc.track_progress or not stability\n",
    "\n",
    "    path_timeseries_output.unlink(missing_ok=True)\n",
    "    \n",
    "    add_flags = [\"-tquery\"]\n",
    "    if tc.interval_time:\n",
    "        add_flags += [f\"-dt={tc.interval_time}\"]\n",
    "    if tc.interval_edge:\n",
    "        add_flags += [f\"-de={tc.interval_edge}\"]\n",
    "    if tc.target_ingest_rate:\n",
    "        add_flags += [f\"-dr={tc.target_ingest_rate}\"]\n",
    "    if tc.delete_window:\n",
    "        add_flags += [f\"-w={tc.delete_window}\"]\n",
    "    if tc.track_progress:\n",
    "        add_flags += [f\"-debug=2\"]\n",
    "    \n",
    "    if stability:\n",
    "        add_flags.append(\"-Stability\")\n",
    "\n",
    "    suffix = \"\".join(add_flags)\n",
    "\n",
    "    kwargs[\"add_flags\"] = add_flags + kwargs.get(\"add_flags\", [])\n",
    "    kwargs[\"suffix\"] = suffix + kwargs.get(\"suffix\", \"\")\n",
    "    path_log = run_algorithm(tc=tc, repeat_index=repeat_index, no_skip=no_skip, **kwargs)\n",
    "\n",
    "    path_timeseries = ts_dir / (path_log.name[:-4] + f\".csv\")\n",
    "    path_timeseries_flow = None\n",
    "    if not no_skip and path_timeseries.exists():\n",
    "        print(f\"Timeseries already exists: {path_timeseries}\")\n",
    "        if stability:\n",
    "            path_timeseries_flow = ts_dir / (path_log.name[:-4] + f\"-flow.csv\")\n",
    "            assert path_timeseries_flow.exists()\n",
    "    else:\n",
    "        assert path_timeseries_output.exists(), \"No timeseries output found\"\n",
    "        path_timeseries_output.rename(path_timeseries)\n",
    "        print(f\"Timeseries saved to: {path_timeseries}\")\n",
    "    \n",
    "        if stability:\n",
    "            path_timeseries_flow = ts_dir / (path_log.name[:-4] + f\"-flow.csv\")\n",
    "            assert path_timeseries_flow_output.exists()\n",
    "            path_timeseries_flow_output.rename(path_timeseries_flow)\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "    return get_ts_result(tc=tc, path_log=path_log, path_timeseries=path_timeseries, path_timeseries_flow=path_timeseries_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaturationTest:\n",
    "    def __init__(self, testcases: list[list[BasicTestCase]], query_intervals: list[int]) -> None:\n",
    "        self.testcases = testcases\n",
    "        self.query_intervals = sorted(query_intervals)\n",
    "        self.common_rates = [(\"Ethereum Transactions\", 12, 4), (\"VisaNet Transactions\", 6000, -11), (\"Worldwide Emails Sent/Received\", 10000, 4)]\n",
    "\n",
    "        indices = self.query_intervals\n",
    "        columns = []\n",
    "        for tcs in testcases:\n",
    "            columns += [f\"{tcs[0].graph.name}-top\", f\"{tcs[0].graph.name}-mid\", f\"{tcs[0].graph.name}-bot\"]\n",
    "        self.results = pd.DataFrame(index=indices, columns=columns)\n",
    "\n",
    "    def run(self) -> None:\n",
    "        for interval in self.query_intervals:\n",
    "            for tcs_graph in self.testcases:\n",
    "                throughputs = []\n",
    "                for tc in tcs_graph:\n",
    "                    tc_ts = TimeseriesTestCase(interval_time=interval, **tc.__dict__)\n",
    "                    result = run_algorithm_ts(tc=tc_ts)\n",
    "                    throughputs.append(result.ingest_rate_actual)\n",
    "                self.results.at[interval, f\"{tcs_graph[0].graph.name}-top\"] = max(throughputs)\n",
    "                self.results.at[interval, f\"{tcs_graph[0].graph.name}-mid\"] = statistics.median(throughputs)\n",
    "                self.results.at[interval, f\"{tcs_graph[0].graph.name}-bot\"] = min(throughputs)\n",
    "        return self.results\n",
    "\n",
    "    def plot(self, figsize) -> None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "        x = self.results.index.astype(int)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xticks(self.results.index)\n",
    "        ax.set_xticklabels(self.results.index)\n",
    "        ax.set(ylim=[1e1, 1e7])\n",
    "        ax.invert_xaxis()\n",
    "        for tcs in self.testcases:\n",
    "            name = tcs[0].graph.name\n",
    "            ax.plot(x, self.results.loc[:, f\"{name}-mid\"], marker = '.', markersize = 5, label=f\"{name}\")\n",
    "            ax.fill_between(x, self.results.loc[:, f\"{name}-top\"].astype(int), self.results.loc[:, f\"{name}-bot\"].astype(int), alpha=0.4)\n",
    "        ax.xaxis.grid(alpha=0.3)\n",
    "        ax.yaxis.grid(alpha=0.3)\n",
    "        fig.legend(bbox_to_anchor=(0.51, 0.92), loc='center', ncol=3, framealpha=1, prop={'size': 7.5})\n",
    "\n",
    "        for label, rate, y_offset in self.common_rates:\n",
    "            lines = ax.plot([min(x), max(x)], [rate]*2)\n",
    "            ax.annotate(f\"{label}\", (max(x), rate), xytext=(1, y_offset), textcoords='offset points', color=lines[0].get_color())\n",
    "        \n",
    "        ax.set_xlabel(f\"Query Interval (days)\", labelpad=6)\n",
    "        ax.set_ylabel(f\"Throughput (events/second)\", labelpad=6)\n",
    "\n",
    "        return fig\n",
    "\n",
    "n = 10\n",
    "saturation_test = SaturationTest(testcases=[tc_eth_transfers[:n], tc_hive_comments[:n], tc_wikipedia_growth[:n], tc_flickr_growth[:n]], query_intervals=[1024, 256, 64, 16, 4, 1])\n",
    "result = saturation_test.run()\n",
    "fig = saturation_test.plot((5,3))\n",
    "fig.savefig(output_dir / \"saturation.pdf\", bbox_inches='tight')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressExperiment():\n",
    "    def __init__(self, testcases: (list[BasicTestCase], str), query_interval: int) -> None:\n",
    "        self.testcases = testcases\n",
    "        self.query_interval = query_interval\n",
    "        self.results = None\n",
    "    \n",
    "    def run(self) -> (pd.DataFrame, pd.DataFrame):\n",
    "        self.results = []\n",
    "        for tc, name in self.testcases:\n",
    "            tc_ts = TimeseriesTestCase(interval_time=self.query_interval, track_progress=True, **tc.__dict__)\n",
    "            result = run_algorithm_ts(tc=tc_ts)\n",
    "            self.results.append((name, result.progress))\n",
    "        return self.results\n",
    "\n",
    "    def plot(self, figsize) -> plt.Figure:\n",
    "        results = self.results if self.results != None else self.run()\n",
    "        fig, axs = plt.subplots(len(results), 1, figsize=figsize)\n",
    "        if len(results) == 1:\n",
    "            axs = [axs]\n",
    "\n",
    "        for ax, (name, progress) in zip(axs, results):\n",
    "            flow_progress = progress.loc[progress[\"type\"] == \"flow\"]\n",
    "            x_max = progress.iloc[-1][\"time\"]\n",
    "            y_max = max(progress.loc[progress[\"type\"] == \"flow\"][\"source-sent\"])*2\n",
    "\n",
    "            ax.plot(\"time\", \"source-sent\", data=flow_progress, marker='.', markersize=5, label=f\"Source Sent\")\n",
    "            ax.plot(\"time\", \"sink-received\", data=flow_progress, marker='.', markersize=5, label=f\"Sink Received\")\n",
    "            ax.vlines(progress.loc[progress[\"type\"] == \"query-triggered\"][\"time\"], 0, y_max, label=f\"Query Triggered\", color=\"red\", linewidth=0.5)\n",
    "            ax.vlines(progress.loc[progress[\"type\"] == \"query-done\"][\"time\"], 0, y_max, label=f\"Query Finished\", color=\"green\", linewidth=0.5)\n",
    "            ax.yaxis.grid(alpha=0.5)\n",
    "            ax.set(xlim=[0, x_max], ylim=[1, y_max], yscale=\"log\")\n",
    "            ax.title.set(text=name, size=10)\n",
    "        \n",
    "        axs[-1].set_xlabel(\"Algorithm Time (ms)\")\n",
    "\n",
    "        handles, labels = axs[-1].get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, bbox_to_anchor=(1, 0.96), loc='upper left', ncol=1, prop={'size': 10})\n",
    "        fig.text(-0.03, 0.56, \"Flow Amount\", va='center', rotation='vertical')\n",
    "        fig.tight_layout(pad=0.5)\n",
    "        return fig\n",
    "\n",
    "progress_experiment = ProgressExperiment([\n",
    "    (tc_hive_comments[0], f\"Subplot 1: Hive-comments, Most Popular (s,t)\"),\n",
    "    (tc_hive_comments[4], f\"Subplot 2: Hive-comments, 5th Most Popular (s,t)\"),\n",
    "    (tc_wikipedia_growth[0], f\"Subplot 3: Wikipedia-growth, Most Popular (s,t)\")\n",
    "    ], 128)\n",
    "# result = progress_experiment.run()\n",
    "fig = progress_experiment.plot((7,5))\n",
    "fig.savefig(output_dir / \"progress.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScalabilityTest():\n",
    "    def __init__(self, testcases: list[BasicTestCase], interval_time: int = None, interval_edge: int = None) -> None:\n",
    "        self.testcases_ts = [\n",
    "            [\n",
    "                TimeseriesTestCase(interval_time=interval_time, interval_edge=interval_edge, threads=t, **tc.__dict__) \n",
    "                for tc in testcases\n",
    "            ]\n",
    "            for t in threads\n",
    "        ]\n",
    "        self.testcases_static = [\n",
    "            [\n",
    "                StaticTestCase(threads=t, **tc.__dict__) \n",
    "                for tc in testcases\n",
    "            ]\n",
    "            for t in threads\n",
    "        ]\n",
    "\n",
    "        indices = [threads]\n",
    "        columns = [\"speedup-static-alg\", \"speedup-static-total\", \"speedup-ts-latency-each\", \"speedup-ts-latency-all\", \"speedup-ts-total-runtime\"]\n",
    "        columns += [\"static-alg\", \"static-total\", \"ts-latency\", \"ts-total-runtime\"]\n",
    "        self.columns_ts = [f\"ts-{tc.get_name()}\" for tc in testcases]\n",
    "        self.columns_static = [f\"static-{tc.get_name()}\" for tc in testcases]\n",
    "        columns += self.columns_ts + self.columns_static\n",
    "        self.results = pd.DataFrame(index=indices, columns=columns)\n",
    "    \n",
    "    def run(self) -> pd.DataFrame:\n",
    "        self._run_timeseries()\n",
    "        self._run_static()\n",
    "        return self.results\n",
    "\n",
    "    def _run_static(self) -> None:\n",
    "        for tc_row in self.testcases_static:\n",
    "            for tc in tc_row:\n",
    "                result = run_algorithm_static(tc=tc, cpu_affinity=True)\n",
    "                self.results.at[tc.threads, f\"static-{tc.get_name()}\"] = result\n",
    "        \n",
    "        for i, row in self.results.iterrows():\n",
    "            # mean\n",
    "            algs, totals = [], []\n",
    "            for c in self.columns_static:\n",
    "                algs.append(row[c].time_alg)\n",
    "                totals.append(row[c].time_general)\n",
    "            self.results.at[i, \"static-alg\"] = statistics.mean(algs)\n",
    "            self.results.at[i, \"static-total\"] = statistics.mean(totals)\n",
    "\n",
    "            # speedup\n",
    "            row_0 = self.results.iloc[0]\n",
    "            speedup_static_alg = []\n",
    "            speedup_static_total = []\n",
    "            for c in self.columns_static:\n",
    "                speedup_static_alg.append(row_0[c].time_alg / row[c].time_alg)\n",
    "                speedup_static_total.append(row_0[c].time_general / row[c].time_general)\n",
    "            self.results.at[i, \"speedup-static-alg\"] = statistics.geometric_mean(speedup_static_alg)\n",
    "            self.results.at[i, \"speedup-static-total\"] = statistics.geometric_mean(speedup_static_total)\n",
    "    \n",
    "    def _run_timeseries(self) -> None:\n",
    "        for tc_row in self.testcases_ts:\n",
    "            for tc in tc_row:\n",
    "                result = run_algorithm_ts(tc=tc, cpu_affinity=True)\n",
    "                self.results.at[tc.threads, f\"ts-{tc.get_name()}\"] = result\n",
    "\n",
    "        for i, row in self.results.iterrows():\n",
    "            # mean\n",
    "            latency_means = []\n",
    "            latencies_all = []\n",
    "            total_runtimes = []\n",
    "            for c in self.columns_ts:\n",
    "                result: TimeseriesResult = row[c]\n",
    "                latency_means.append(result.latency_mean)\n",
    "                latencies_all += result.timeseries.loc[:, \"Latency\"].tolist()\n",
    "                total_runtimes.append(result.time_termination)\n",
    "            self.results.at[i, \"ts-latency\"] = statistics.mean(latency_means)\n",
    "            self.results.at[i, \"ts-total-runtime\"] = statistics.mean(total_runtimes)\n",
    "\n",
    "            # speedup\n",
    "            row_0 = self.results.iloc[0]\n",
    "            speedup_latency_each, speedup_latency_mean, speedup_total_runtime = [], [], []\n",
    "            for c in self.columns_ts:\n",
    "                speedup_latency_mean.append(row_0[c].latency_mean / row[c].latency_mean)\n",
    "                speedup_total_runtime.append(row_0[c].time_termination / row[c].time_termination)\n",
    "                speedup_latency_each += list(row_0[c].timeseries.loc[:, \"Latency\"] / row[c].timeseries.loc[:, \"Latency\"])\n",
    "                assert(row_0[c].timeseries.shape == row[c].timeseries.shape)\n",
    "\n",
    "            self.results.at[i, \"speedup-ts-latency-each\"] = statistics.geometric_mean(speedup_latency_each)\n",
    "            self.results.at[i, \"speedup-ts-latency-all\"] = statistics.geometric_mean(speedup_latency_mean)\n",
    "            self.results.at[i, \"speedup-ts-total-runtime\"] = statistics.geometric_mean(speedup_total_runtime)\n",
    "\n",
    "scalability_test = ScalabilityTest(testcases=tc_wikipedia_growth[:5], interval_time=128)\n",
    "# scalability_test.run()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowTest():\n",
    "    def __init__(self, testcases: list[BasicTestCase], delete_window: int, query_intervals: list[int]) -> None:\n",
    "        self.delete_window = delete_window\n",
    "        self.query_intervals = query_intervals\n",
    "        self.testcases_ts = [\n",
    "            [\n",
    "                (interval, [\n",
    "                    TimeseriesTestCase(interval_time=interval, **tc.__dict__)\n",
    "                    for tc in tcs\n",
    "                ])\n",
    "                for interval in query_intervals\n",
    "            ]\n",
    "            for tcs in testcases\n",
    "        ]\n",
    "\n",
    "        self.columns_runtime = []\n",
    "        self.columns_latency = []\n",
    "        for i in query_intervals:\n",
    "            self.columns_runtime += [f\"runtime-{i}-a\", f\"runtime-{i}-d\"]\n",
    "        for i in query_intervals:\n",
    "            self.columns_latency += [f\"latency-{i}-a\", f\"latency-{i}-d\"]\n",
    "        self.results = pd.DataFrame(index=[tcs[0].graph.name for tcs in testcases], columns=self.columns_runtime+self.columns_latency)\n",
    "\n",
    "    def run(self) -> pd.DataFrame:\n",
    "        for tc_row in self.testcases_ts:\n",
    "            for interval, tcs in tc_row:\n",
    "                add_termination, add_latency, del_termination, del_latency = [], [], [], []\n",
    "                for tc_add in tcs:\n",
    "                    assert interval == tc_add.interval_time\n",
    "\n",
    "                    tc_del = TimeseriesTestCase(**tc_add.__dict__)\n",
    "                    tc_del.delete_window = self.delete_window\n",
    "\n",
    "                    result_add = run_algorithm_ts(tc=tc_add)\n",
    "                    result_del = run_algorithm_ts(tc=tc_del)\n",
    "\n",
    "                    add_termination.append(result_add.time_termination)\n",
    "                    add_latency.append(result_add.latency_mean)\n",
    "                    del_termination.append(result_del.time_termination)\n",
    "                    del_latency.append(result_del.latency_mean)\n",
    "                print(add_latency)\n",
    "                self.results.at[tc_add.graph.name, f\"runtime-{interval}-a\"] = np.nanmean(add_termination)\n",
    "                self.results.at[tc_add.graph.name, f\"latency-{interval}-a\"] = np.nanmean(add_latency)\n",
    "                self.results.at[tc_del.graph.name, f\"runtime-{interval}-d\"] = np.nanmean(del_termination)\n",
    "                self.results.at[tc_del.graph.name, f\"latency-{interval}-d\"] = np.nanmean(del_latency)\n",
    "        self.results = self.results / 1000 # convert to seconds\n",
    "        return self.results\n",
    "\n",
    "    def save(self) -> None:\n",
    "        results = self.run()\n",
    "\n",
    "        tab_total = \"% Total Runtime\\n\"\n",
    "        df_total = results.loc[:, self.columns_runtime]\n",
    "        tab_total += \"& \" + \" & \".join([c[8:] for c in self.columns_runtime]) + \" \\\\\\\\\\n\"\n",
    "        for index, row in df_total.iterrows():\n",
    "            tab_total += index + \" & \" + \" & \".join([f\"{v:.2f}\" for v in row.values]) + \" \\\\\\\\\\n\"\n",
    "\n",
    "        tab_latency = \"% Average Latency\\n\"\n",
    "        df_latency = results.loc[:, self.columns_latency]\n",
    "        tab_latency += \"& \" + \" & \".join([c[8:] for c in self.columns_latency]) + \" \\\\\\\\\\n\"\n",
    "        for index, row in df_latency.iterrows():\n",
    "            tab_latency += index + \" & \" + \" & \".join([f\"{v:.2f}\" for v in row.values]) + \" \\\\\\\\\\n\"\n",
    "\n",
    "        tab_deletions = tab_total + \"\\n\" + tab_latency\n",
    "        with open(output_dir / \"tab-deletions.txt\", \"w\") as f:\n",
    "            f.write(tab_deletions)\n",
    "\n",
    "n = 10\n",
    "sliding_window = SlidingWindowTest(testcases=[tc_eth_transfers[:n], tc_hive_comments[:n], tc_wikipedia_growth[:n], tc_flickr_growth[:n]], delete_window=120, query_intervals=[128, 64, 32])\n",
    "result = sliding_window.run()\n",
    "sliding_window.save()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_ts(dfs: list[pd.DataFrame]) -> pd.DataFrame:\n",
    "    # TODO: Fix this\n",
    "    assert len(dfs) > 0\n",
    "    output_df = pd.DataFrame()\n",
    "    output_df.loc[:, \"Date\"] = pd.to_datetime(output_df.loc[:, \"Date\"])\n",
    "    return output_df\n",
    "\n",
    "class RateLimitingTest():\n",
    "    def __init__(self, testcases: list[BasicTestCase], delete_window: int, query_intervals: list[int], ingest_rates: list[int]) -> None:\n",
    "        self.delete_window = delete_window\n",
    "        self.testcases_basic = testcases\n",
    "        self.query_intervals = query_intervals\n",
    "        self.ingest_rates = ingest_rates\n",
    "        self.testcases_ts = [\n",
    "            [\n",
    "                [\n",
    "                    TimeseriesTestCase(interval_time=interval, delete_window=delete_window, target_ingest_rate=rate, **tc.__dict__)\n",
    "                    for tc in testcases\n",
    "                ]\n",
    "                for rate in ingest_rates\n",
    "            ]\n",
    "            for interval in query_intervals\n",
    "        ]\n",
    "\n",
    "        indices = pd.MultiIndex.from_product([query_intervals, ingest_rates])\n",
    "        columns = [tc.get_name() for tc in testcases] + [\"ingest-rate\", \"latency-average\"]\n",
    "        self.results = pd.DataFrame(index=indices, columns=columns)\n",
    "\n",
    "    def run(self) -> pd.DataFrame:\n",
    "        for testcases_intervals in self.testcases_ts:\n",
    "            for testcases_rates in testcases_intervals:\n",
    "                for tc in testcases_rates:\n",
    "                    result = run_algorithm_ts(tc=tc)\n",
    "                    self.results.at[(tc.interval_time, tc.target_ingest_rate), tc.get_name()] = result\n",
    "                    self.results.at[(tc.interval_time, tc.target_ingest_rate), \"ingest-rate\"] = result.ingest_rate_actual\n",
    "                    self.results.at[(tc.interval_time, tc.target_ingest_rate), \"latency-average\"] = result.latency_mean\n",
    "        return self.results \n",
    "    \n",
    "    def plot_1(self, y_max, x_min, figsize, legend_box) -> plt.Figure:\n",
    "        name = self.testcases_basic[0].name\n",
    "        timeseries = self.results.iloc[0][name].timeseries\n",
    "        timestamps, e = pd.to_datetime(timeseries[\"Date\"]), timeseries[\"EdgeCount\"]\n",
    "        min_ts, max_ts, max_e = min(timestamps), max(timestamps), max(e)\n",
    "        print(f\"min(ts)={min_ts} max(ts)={max_ts} max(e)={max_e}\")\n",
    "        tc_names = [tc.get_name() for tc in self.testcases_basic]\n",
    "\n",
    "        fig, axs = plt.subplots(len(self.query_intervals), len(self.ingest_rates), sharex=True, sharey=True, figsize=figsize)\n",
    "\n",
    "        for row_index, interval in enumerate(self.query_intervals):\n",
    "            for column_index, rate in enumerate(self.ingest_rates):\n",
    "                ax = axs[row_index, column_index]\n",
    "\n",
    "                print(f\"{interval}, {rate}\")\n",
    "                results = self.results.loc[(interval, rate), tc_names].values.tolist()\n",
    "                ts = get_averaged_ts([r.timeseries for r in results])\n",
    "                print(ts)\n",
    "\n",
    "                x, y1 = ts[\"Date\"], ts[\"Latency\"]\n",
    "                # ax.patch.set_visible(False)\n",
    "                # ax.set(xlim=[x_min, max_ts], ylim=[0,y_max], zorder=2, xticks=[])\n",
    "                ax.plot(x, y1, marker = '.', markersize = 5, color=\"chocolate\", label=\"Latency (ms) (left)\")\n",
    "                ax.fill_between(x, y1, alpha=0.2, facecolor=\"red\", edgecolor=None)\n",
    "        \n",
    "        fig.tight_layout(pad=0.5)\n",
    "        return fig\n",
    "    \n",
    "    def plot_2(self, figsize) -> plt.Figure:\n",
    "        fig, axs = plt.subplots(len(self.query_intervals), 1, sharex=True, sharey=True, figsize=figsize)\n",
    "        tc_names = [tc.get_name() for tc in self.testcases_basic]\n",
    "\n",
    "        for row_index, interval in enumerate(self.query_intervals):\n",
    "            ax = axs[row_index]\n",
    "            x, y_mid, y_top, y_bottom = [r / 1e6 for r in self.ingest_rates], [], [], [] # [r / 1e6 for r in self.ingest_rates]\n",
    "            for rate in self.ingest_rates:\n",
    "                results = self.results.loc[(interval, rate), tc_names]\n",
    "                latencies = []\n",
    "                for result in results:\n",
    "                    latencies += result.timeseries.loc[:, \"Latency\"].values.tolist()\n",
    "                # rates = [result.ingest_rate_actual for result in results]\n",
    "                # x.append(statistics.mean(rates) / 1e6)\n",
    "                y_mid.append(statistics.median(latencies) / 1000)\n",
    "                y_top.append(np.percentile(latencies, 80) / 1000)\n",
    "                y_bottom.append(np.percentile(latencies, 20) / 1000)\n",
    "            \n",
    "            \n",
    "            ax.plot(x, y_mid, marker = '.', markersize = 5, color=\"chocolate\", label=\"Latency (ms)\")\n",
    "            ax.fill_between(x, y_bottom, y_top, alpha=0.2)\n",
    "            # ax.set_ylabel(f\"{interval} days\", labelpad=7)\n",
    "            # ax.set_ylabel(f\"Result Latency (seconds)\", labelpad=7)\n",
    "            ax.annotate(f\"Query Interval: {interval} days\", xy=(0.99, 0.96), xycoords='axes fraction', horizontalalignment='right', verticalalignment='top')\n",
    "        \n",
    "        ax.set(ylim=[0, 6])\n",
    "        ax.invert_xaxis()\n",
    "        axs[-1].set_xlabel(f\"Ingestion Rate (million events/second)\", labelpad=7)\n",
    "        fig.text(-0.03, 0.56, \"Result Latency (seconds)\", va='center', rotation='vertical')\n",
    "\n",
    "        fig.tight_layout(pad=0.5)\n",
    "        return fig\n",
    "\n",
    "rate_limiting_test = RateLimitingTest(testcases=tc_hive_comments[:1], delete_window=0, query_intervals=[64, 32], ingest_rates=list(range(300000, 0, -50000))+[25000])\n",
    "# rate_limiting_test = RateLimitingTest(testcases=tc_wikipedia_growth[:1], delete_window=0, query_intervals=[512, 256, 128, 64, 32], ingest_rates=range(5000000, 2000000, -250000))\n",
    "results = rate_limiting_test.run()\n",
    "# fig = rate_limiting_test.plot_1(0, 0, (6, 4), None)\n",
    "fig = rate_limiting_test.plot_2((5, 3))\n",
    "fig.savefig(output_dir / \"rate-limiting.pdf\", bbox_inches='tight')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StabilityTest:\n",
    "    def __init__(self, tc: BasicTestCase, interval_time: int, interval_edge: int) -> None:\n",
    "        self.testcase = TimeseriesTestCase(interval_time=interval_time, interval_edge=interval_edge, **tc.__dict__)\n",
    "        self.count_columns = [\"total-flow-vertex-dynamic\", \"total-flow-vertex-static\", \"same-flow-vertex-dynamic\", \"same-flow-vertex-static\"]\n",
    "        self.percentage_columns = [\"same-percent-dynamic\", \"same-percent-static\"]\n",
    "        self.columns = [\"latency-dynamic\", \"latency-static\"] + self.percentage_columns + self.count_columns\n",
    "        self.count_columns_original = [\"VertexNumInFlowDynamic\", \"VertexNumInFlowStatic\", \"VertexFlowSameDynamic\", \"VertexFlowSameStatic\"]\n",
    "    \n",
    "    def run(self) -> pd.DataFrame:\n",
    "        result_stability = run_algorithm_ts(tc=self.testcase, stability=True)\n",
    "        result_latency = run_algorithm_ts(tc=self.testcase)\n",
    "\n",
    "        index = pd.to_datetime(result_latency.timeseries.loc[:, \"Date\"])\n",
    "        self.result = pd.DataFrame(index=index, columns=self.columns)\n",
    "\n",
    "        self.result.loc[:, \"latency-dynamic\"] = result_latency.timeseries.loc[:, \"Latency\"]\n",
    "        counts = result_stability.timeseries_flow.tail(self.result.shape[0]).loc[:, self.count_columns_original + [\"StaticLatency\"]].values\n",
    "        self.result.loc[:, self.count_columns + [\"latency-static\"]] = counts\n",
    "        self.result.loc[:, \"same-percent-dynamic\"] = self.result.loc[:, \"same-flow-vertex-dynamic\"] / self.result.loc[:, \"total-flow-vertex-dynamic\"]\n",
    "        self.result.loc[:, \"same-percent-static\"] = self.result.loc[:, \"same-flow-vertex-static\"] / self.result.loc[:, \"total-flow-vertex-static\"]\n",
    "        print(result_latency.ingest_rate_actual)\n",
    "        return self.result\n",
    "\n",
    "    def plot(self, y_min_percentage, y_max_latency, figsize) -> plt.Figure:\n",
    "        result = self.run()\n",
    "        x = result.index\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax.plot(result.index, result.loc[:, \"same-percent-dynamic\"], marker = '.', markersize = 5, label=f\"Same Vertices, Dynamic (Left)\")\n",
    "        ax.plot(result.index, result.loc[:, \"same-percent-static\"], marker = '.', markersize = 5, label=f\"Same Vertices, Static (Left)\")\n",
    "\n",
    "        ax.yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "        ax.tick_params(axis='x', labelrotation = 45)\n",
    "        ax.set_xticks(x[1:])\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "        ax.set(xlim=[x[1], x[-1]], ylim=[y_min_percentage, 1], ylabel=f\"% of Same Vertices\", zorder=1)\n",
    "        ax.patch.set_visible(False)\n",
    "        ax.xaxis.grid(alpha=0.3)\n",
    "        ax.yaxis.grid(alpha=0.3)\n",
    "        ax.set_xlabel(\"Graph Evolution (Date)\", labelpad=7)\n",
    "\n",
    "        ax = ax.twinx()\n",
    "        ax.plot(result.index, result.loc[:, \"latency-dynamic\"] / 1000, marker = 'x', markersize = 5, linestyle='dashed', label=f\"Latency, Dynamic (Right)\")\n",
    "        ax.plot(result.index, result.loc[:, \"latency-static\"] / 1000, marker = 'x', markersize = 5, linestyle='dashed', label=f\"Latency, Static (Right)\")\n",
    "        ax.set(ylim=[0, y_max_latency], ylabel=f\"Result Latency (s)\", zorder=1)\n",
    "\n",
    "        fig.legend(bbox_to_anchor=(0.51, 1.03), loc='center', ncol=2, framealpha=1, prop={'size': 7.5})\n",
    "        fig.tight_layout(pad=0.5)\n",
    "        return fig\n",
    "\n",
    "stability_test = StabilityTest(tc_wikipedia_growth[0], interval_time=128, interval_edge=None)\n",
    "result = stability_test.run()\n",
    "fig = stability_test.plot(y_min_percentage=0, y_max_latency=10, figsize=(6, 2.5))\n",
    "fig.savefig(output_dir / \"stability.pdf\", bbox_inches='tight')\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2023-sc-poter-oA663jYI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
