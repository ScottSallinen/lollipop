{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for CPEN 534 Course projects\n",
    "\n",
    "This notebook contains the scripts to run all experiments and generate all figures in the poster (and its Extended Abstract).\n",
    "Please follow the these step:\n",
    "1. Run `pipenv install` to install the python dependencies specified in `Pipfile` and `Pipfile.lock`.\n",
    "2. Ensure `go version` is `1.22.1`.\n",
    "3. Update the values of `path_to_graph`, `path_to_project`, and `threads` in the next cell.\n",
    "4. Run all cells in this notebook with the python environment created in Step 1.\n",
    "5. The results will be saved in the directory `results/2024-cpen534/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "project_path = \"~/projects/lollipop\" # root of the repository\n",
    "path_hive_comments = \"~/hive-comments.txt\"\n",
    "path_wikipedia_growth = \"~/wikipedia-growth.txt\"\n",
    "path_eth_transfers = \"~/eth-transfers-t200m.txt.p\"\n",
    "path_flickr = \"~/flickr-growth.txt\"\n",
    "path_roadnet = \"~/roadNet-CA.txt.shuffled\" # shuffled with random edge weights added # ignore this for now\n",
    "\n",
    "default_thread = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re\n",
    "import time\n",
    "import statistics\n",
    "import os, signal\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go = Path(shutil.which(\"go\"))\n",
    "project_path = Path(project_path).expanduser()\n",
    "path_hive_comments = Path(path_hive_comments).expanduser()\n",
    "path_wikipedia_growth = Path(path_wikipedia_growth).expanduser()\n",
    "path_eth_transfers = Path(path_eth_transfers).expanduser()\n",
    "path_flickr = Path(path_flickr).expanduser()\n",
    "path_roadnet = Path(path_roadnet).expanduser()\n",
    "assert go.exists()\n",
    "assert project_path.exists()\n",
    "assert path_hive_comments.exists()\n",
    "assert path_wikipedia_growth.exists()\n",
    "assert path_eth_transfers.exists()\n",
    "assert path_flickr.exists()\n",
    "assert path_roadnet.exists()\n",
    "\n",
    "# TODO: check hashes of graph files\n",
    "\n",
    "# push_relabel_code = project_path / \"cmd\" / f\"lp-push-relabel\"\n",
    "# assert push_relabel_code.exists()\n",
    "pagerank_code = project_path / \"cmd\" / f\"lp-pagerank\"\n",
    "assert pagerank_code.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_directory(top_dir: Path):\n",
    "    results_dir = top_dir / f\"2024-cpen534\"\n",
    "    log_dir = results_dir / \"log\"\n",
    "    ts_dir = results_dir / \"ts\"\n",
    "    output_dir = results_dir / \"output\"\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    log_dir.mkdir(exist_ok=True)\n",
    "    ts_dir.mkdir(exist_ok=True)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    return results_dir, output_dir, log_dir, ts_dir\n",
    "\n",
    "(project_path / \"results\").mkdir(exist_ok=True)\n",
    "results_dir, output_dir, log_dir, ts_dir = create_results_directory(project_path / \"results\")\n",
    "path_timeseries_output = project_path / \"results\" / \"push-relabel-timeseries.csv\"\n",
    "path_timeseries_flow_output = project_path / \"results\" / \"push-relabel-timeseries-flow.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(kw_only=True)\n",
    "class Graph:\n",
    "    name: str\n",
    "    path: Path\n",
    "    pw: int\n",
    "    pt: int\n",
    "    undirected: bool = False\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class ExperimentConfig:\n",
    "    graph: Graph\n",
    "    st_index: int\n",
    "    s: int\n",
    "    t: int\n",
    "\n",
    "    def get_name(self) -> str:\n",
    "        return f\"{self.graph.name}-{self.st_index}\"\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class BasicTestCase(ExperimentConfig):\n",
    "    threads: int = default_thread\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class StaticTestCase(BasicTestCase):\n",
    "    pass\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class DynamicTestCase(BasicTestCase):\n",
    "    target_ingest_rate: int = 0\n",
    "    delete_window: int = 0\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class TimeseriesTestCase(DynamicTestCase):\n",
    "    interval_time: int = None\n",
    "    interval_edge: int = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        assert (self.interval_time and not self.interval_edge) or \\\n",
    "            (not self.interval_time and self.interval_edge), \\\n",
    "            \"Exactly one of dt or de must set\"\n",
    "\n",
    "graph_hive_comments = Graph(name=\"Hive-comments\", path=path_hive_comments, pw=None, pt=1)\n",
    "graph_wikipedia_growth = Graph(name=\"Wikipedia-growth\", path=path_wikipedia_growth, pw=None, pt=2)\n",
    "graph_eth_transfers = Graph(name=\"Eth-transfers\", path=path_eth_transfers, pw=1, pt=2)\n",
    "graph_flickr_growth = Graph(name=\"Flickr-growth\", path=path_flickr, pw=None, pt=2)\n",
    "graph_roadnet = Graph(name=\"RoadNet-CA\", path=path_roadnet, pw=1, pt=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(g: Graph, xlog: bool = False):\n",
    "    degrees = dict()\n",
    "    with open(g.path) as file:\n",
    "        for line in file:\n",
    "            src, _ = line.split(maxsplit=1)\n",
    "            if src not in degrees:\n",
    "                degrees[src] = 1\n",
    "            else:\n",
    "                degrees[src] += 1\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
    "    ax.set(title=f'{g.name}', xlabel='Out Degree', ylabel='# of Vertices', yscale='log', xlim=[0, max(degrees.values())])\n",
    "    if xlog:\n",
    "        ax.set(xscale='log')\n",
    "    ax.hist(degrees.values(), bins=100)\n",
    "\n",
    "    fig.tight_layout(pad=0)\n",
    "    fig.savefig(output_dir / f\"degree-histogram-{g.name}.pdf\", bbox_inches='tight')\n",
    "\n",
    "plot_histogram(graph_wikipedia_growth)\n",
    "plot_histogram(graph_hive_comments, xlog=False)\n",
    "plot_histogram(graph_flickr_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Result:\n",
    "    test_case: TimeseriesTestCase\n",
    "    time_alg: int\n",
    "    # time_general: int\n",
    "    total_msg: int\n",
    "    total_remote_msg: int\n",
    "    maxThreadMsgRecv: int\n",
    "    maxThreadMsgRecv_ratio: float # ratio to avg\n",
    "    maxThreadRemoteMsgRecv: int\n",
    "    maxThreadRemoteMsgRecv_ratio: float\n",
    "    maxThreadVertices: int\n",
    "    maxThreadVertices_ratio: float\n",
    "    maxThreadEdges: int\n",
    "    maxThreadEdges_ratio: float\n",
    "\n",
    "def get_result(tc: TimeseriesTestCase, path_log: Path) -> Result:\n",
    "    assert isinstance(tc, StaticTestCase)\n",
    "\n",
    "    log = path_log.read_text()\n",
    "\n",
    "    time_alg = re.findall(r\"Termination: ([0-9]+)\", log)\n",
    "    assert len(time_alg) == 1 \n",
    "    time_alg = int(time_alg[0])\n",
    "\n",
    "    msg_stat = re.findall(r\"maxThreadMsgRecv \\(ratio to avg\\): ([0-9]+) \\(([+-]?\\d+(?:\\.\\d+)?)\\) maxThreadRemoteMsgRecv \\(ratio to avg\\): ([0-9]+) \\(([+-]?\\d+(?:\\.\\d+)?)\\)\", log)\n",
    "    assert len(msg_stat) == 4\n",
    "    maxThreadMsgRecv = int(msg_stat[0])\n",
    "    maxThreadMsgRecv_ratio = float(msg_stat[1])\n",
    "    maxThreadRemoteMsgRecv = int(msg_stat[2])\n",
    "    maxThreadVertices_ratio = float(msg_stat[3])\n",
    "\n",
    "    # time_general = re.findall(r\"Total including streaming: ([0-9]+)\", log)\n",
    "    # assert len(time_general) == 1 \n",
    "    # time_general = int(time_general[0])\n",
    "    \n",
    "    return Result(test_case=tc, time_alg=time_alg, time_general=time_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(tc: BasicTestCase, repeat_index: int = 0, correctness: bool = True, add_flags: list[str] = [], suffix: str = \"\", no_skip: bool = False) -> Path:\n",
    "    assert isinstance(tc, BasicTestCase)\n",
    "\n",
    "    # compile command and log filename\n",
    "    cmd = [go, \"run\", push_relabel_code, \"-nc\", f\"-t={tc.threads}\", f\"-g={tc.graph.path}\"]\n",
    "    log_filename = f\"push-relabel-t={tc.threads}-g={tc.graph.path.name}\"\n",
    "    if tc.graph.undirected:\n",
    "        cmd.append(\"-u\")\n",
    "        log_filename += \"-u\"\n",
    "    if tc.graph.pw:\n",
    "        cmd += [f\"-pw={tc.graph.pw}\"]\n",
    "        log_filename += f\"-pw={tc.graph.pw}\"\n",
    "    if tc.graph.pt:\n",
    "        cmd += [f\"-pt={tc.graph.pt}\"]\n",
    "        log_filename += f\"-pt={tc.graph.pt}\"\n",
    "\n",
    "    cmd += [f\"-S={tc.s}\", f\"-T={tc.t}\"]\n",
    "    log_filename += f\"-S={tc.s}-T={tc.t}\"\n",
    "\n",
    "    if correctness:\n",
    "        cmd += [\"-c\"]\n",
    "        log_filename += \"-c\"\n",
    "\n",
    "    cmd += add_flags\n",
    "    log_filename += f\"{suffix}.{repeat_index}.log\"\n",
    "\n",
    "    # Run command\n",
    "    log_path = log_dir / log_filename\n",
    "    print(f\"Command: {cmd}\")\n",
    "    print(f\"Log path: {log_path}\")\n",
    "\n",
    "    if (not no_skip) and log_path.exists():\n",
    "        print(f\"Skipped as the log file exists\")\n",
    "        return log_path\n",
    "\n",
    "    path_log_temp = log_dir / f\"_running-{log_filename}\"\n",
    "    with open(path_log_temp, \"w+t\") as log_file:\n",
    "        def preexec_fn():\n",
    "            os.setpgrp()\n",
    "        process = sp.Popen(cmd, cwd=project_path, stdout=log_file, stderr=sp.STDOUT, preexec_fn=preexec_fn)\n",
    "        time.sleep(0.5)\n",
    "        try:\n",
    "            returncode = process.wait()\n",
    "        except KeyboardInterrupt as ki:\n",
    "            os.killpg(os.getpgid(process.pid), signal.SIGTERM)\n",
    "            process.kill()\n",
    "            raise ki\n",
    "        if returncode != 0:\n",
    "            assert False, f\"Return code is none-zero: {returncode}\"\n",
    "    \n",
    "    path_log_temp.rename(log_path)\n",
    "    print(f\"Log saved\")\n",
    "    \n",
    "    return log_path\n",
    "\n",
    "def run_algorithm_static(tc: StaticTestCase, **kwargs) -> StaticResult:\n",
    "    assert isinstance(tc, StaticTestCase)\n",
    "\n",
    "    path_log = run_algorithm(tc=tc, **kwargs)\n",
    "    return get_static_result(tc=tc, path_log=path_log)\n",
    "\n",
    "def run_algorithm_ts(tc: TimeseriesTestCase, repeat_index: int = 0, stability: bool = False, no_skip: bool = False, **kwargs) -> TimeseriesResult:\n",
    "    assert isinstance(tc, TimeseriesTestCase)\n",
    "    assert (tc.interval_time and not tc.interval_edge) or (not tc.interval_time and tc.interval_edge), \"Exactly one of dt or de must set\"\n",
    "    assert not tc.track_progress or not stability\n",
    "\n",
    "    path_timeseries_output.unlink(missing_ok=True)\n",
    "    \n",
    "    add_flags = [\"-tquery\"]\n",
    "    if tc.interval_time:\n",
    "        add_flags += [f\"-dt={tc.interval_time}\"]\n",
    "    if tc.interval_edge:\n",
    "        add_flags += [f\"-de={tc.interval_edge}\"]\n",
    "    if tc.target_ingest_rate:\n",
    "        add_flags += [f\"-dr={tc.target_ingest_rate}\"]\n",
    "    if tc.delete_window:\n",
    "        add_flags += [f\"-w={tc.delete_window}\"]\n",
    "    if tc.track_progress:\n",
    "        add_flags += [f\"-debug=2\"]\n",
    "    \n",
    "    if stability:\n",
    "        add_flags.append(\"-Stability\")\n",
    "\n",
    "    suffix = \"\".join(add_flags)\n",
    "\n",
    "    kwargs[\"add_flags\"] = add_flags + kwargs.get(\"add_flags\", [])\n",
    "    kwargs[\"suffix\"] = suffix + kwargs.get(\"suffix\", \"\")\n",
    "    path_log = run_algorithm(tc=tc, repeat_index=repeat_index, no_skip=no_skip, **kwargs)\n",
    "\n",
    "    path_timeseries = ts_dir / (path_log.name[:-4] + f\".csv\")\n",
    "    path_timeseries_flow = None\n",
    "    if not no_skip and path_timeseries.exists():\n",
    "        print(f\"Timeseries already exists: {path_timeseries}\")\n",
    "        if stability:\n",
    "            path_timeseries_flow = ts_dir / (path_log.name[:-4] + f\"-flow.csv\")\n",
    "            assert path_timeseries_flow.exists()\n",
    "    else:\n",
    "        assert path_timeseries_output.exists(), \"No timeseries output found\"\n",
    "        path_timeseries_output.rename(path_timeseries)\n",
    "        print(f\"Timeseries saved to: {path_timeseries}\")\n",
    "    \n",
    "        if stability:\n",
    "            path_timeseries_flow = ts_dir / (path_log.name[:-4] + f\"-flow.csv\")\n",
    "            assert path_timeseries_flow_output.exists()\n",
    "            path_timeseries_flow_output.rename(path_timeseries_flow)\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "    return get_ts_result(tc=tc, path_log=path_log, path_timeseries=path_timeseries, path_timeseries_flow=path_timeseries_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaturationTest:\n",
    "    def __init__(self, testcases: list[list[BasicTestCase]], query_intervals: list[int], plot_latency: bool = False) -> None:\n",
    "        self.testcases = testcases\n",
    "        self.query_intervals = sorted(query_intervals)\n",
    "        self.common_rates = [(\"VisaNet Transactions\", 6000, -13), (\"Worldwide Emails Sent/Received\", 10000, 4.5)]\n",
    "        # (\"Ethereum Transactions\", 12, 4), \n",
    "        self.plot_latency = plot_latency\n",
    "\n",
    "        indices = self.query_intervals\n",
    "        columns = []\n",
    "        for tcs in testcases:\n",
    "            columns += [f\"{tcs[0].graph.name}-top\", f\"{tcs[0].graph.name}-mid\", f\"{tcs[0].graph.name}-bot\"]\n",
    "        self.results = pd.DataFrame(index=indices, columns=columns)\n",
    "\n",
    "    def run(self) -> None:\n",
    "        for interval in self.query_intervals:\n",
    "            for tcs_graph in self.testcases:\n",
    "                ys = []\n",
    "                for tc in tcs_graph:\n",
    "                    tc_ts = TimeseriesTestCase(interval_time=interval, **tc.__dict__)\n",
    "                    result = run_algorithm_ts(tc=tc_ts)\n",
    "                    ys.append(result.latency_mean/1000 if self.plot_latency else float(result.ingest_rate_actual))\n",
    "                self.results.at[interval, f\"{tcs_graph[0].graph.name}-top\"] = max(ys)\n",
    "                self.results.at[interval, f\"{tcs_graph[0].graph.name}-mid\"] = statistics.median(ys)\n",
    "                self.results.at[interval, f\"{tcs_graph[0].graph.name}-bot\"] = min(ys)\n",
    "        return self.results\n",
    "\n",
    "    def plot(self, figsize) -> None:\n",
    "        ymin, ymax = (0, 5) if self.plot_latency else (3e3, 1e7)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "        x = self.results.index.astype(int)\n",
    "        ax.set_xscale('log')\n",
    "        if not self.plot_latency:\n",
    "            ax.set_yscale('log')\n",
    "        ax.set_xticks(self.results.index)\n",
    "        ax.set_xticklabels(self.results.index)\n",
    "        ax.set(ylim=[ymin, ymax])\n",
    "        ax.invert_xaxis()\n",
    "        for tcs, mk, ms, color in zip(self.testcases, [\"x\", \"d\", \".\"], [5, 4, 7], [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"]):\n",
    "            name = tcs[0].graph.name\n",
    "            ax.plot(x, self.results.loc[:, f\"{name}-mid\"], mk+\"-\", markersize=ms, color=color, label=f\"{name}\")\n",
    "            ax.plot(x, self.results.loc[:, f\"{name}-top\"], mk+\"--\", markersize=ms, color=color, alpha=0.7)\n",
    "            ax.plot(x, self.results.loc[:, f\"{name}-bot\"], mk+\"--\", marker=mk, markersize=ms, color=color, alpha=0.7)\n",
    "            ax.fill_between(x, self.results.loc[:, f\"{name}-top\"].astype(float), self.results.loc[:, f\"{name}-bot\"].astype(float), color=color, alpha=0.3)\n",
    "        \n",
    "        # ax.plot(x, df.loc[:, \"(C)onstruction Only\"] / 1000, \"x-\", color=\"chocolate\", label=\"(C)onstruction Only\", markersize=5)\n",
    "        # ax.plot(x, df.loc[:, \"(S)tatic\"] / 1000, \"D-\", color=\"purple\", label=\"(S)tatic\", markersize=3)\n",
    "        # ax.plot(x, df.loc[:, \"(C)+(S)\"] / 1000, \"s-\", color=\"firebrick\", label=\"(C)+(S)\", markersize=3)\n",
    "        # ax.plot(x, df.loc[:, \"Dynamic\"] / 1000, \".-\", color=\"royalblue\", label=\"Dynamic\", markersize=5)\n",
    "\n",
    "\n",
    "        ax.xaxis.grid(alpha=0.3)\n",
    "        ax.yaxis.grid(alpha=0.3)\n",
    "        fig.legend(bbox_to_anchor=(0.51, 0.92), loc='center', ncol=3, framealpha=1, prop={'size': 7.5})\n",
    "\n",
    "        xlim = ax.get_xlim()\n",
    "        ax.set_xlim([1024*1.1, 1*0.9])\n",
    "        if not self.plot_latency:\n",
    "            for label, rate, y_offset in self.common_rates:\n",
    "                lines = ax.plot([xlim[0], xlim[1]], [rate]*2, '--')\n",
    "                ax.annotate(f\"{label}\", (max(x), rate), xytext=(1, y_offset), textcoords='offset points', color=lines[0].get_color())\n",
    "\n",
    "        ax.set_xlabel(f\"Query Interval (dataset days)\", labelpad=6)\n",
    "        ax.set_ylabel(f\"Mean Latency During Evolution (second)\" if self.plot_latency else \"Throughput (events/second)\", labelpad=6)\n",
    "\n",
    "        ax.set(frame_on=False)\n",
    "        ax.tick_params(bottom=False, left=False)\n",
    "        ax.minorticks_off()\n",
    "\n",
    "        return fig\n",
    "\n",
    "n = 10\n",
    "saturation_test = SaturationTest(testcases=[tc_hive_comments[:n]], query_intervals=[1024, 256, 64, 16, 4, 1], plot_latency=True)\n",
    "result = saturation_test.run()\n",
    "fig = saturation_test.plot((6,3))\n",
    "fig.savefig(output_dir / \"saturation.pdf\", bbox_inches='tight')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressExperiment():\n",
    "    def __init__(self, testcases: (list[BasicTestCase], str), query_interval: int) -> None:\n",
    "        self.testcases = testcases\n",
    "        self.query_interval = query_interval\n",
    "        self.results = None\n",
    "    \n",
    "    def run(self) -> (pd.DataFrame, pd.DataFrame):\n",
    "        self.results = []\n",
    "        for tc, name in self.testcases:\n",
    "            tc_ts = TimeseriesTestCase(interval_time=self.query_interval, track_progress=True, **tc.__dict__)\n",
    "            result = run_algorithm_ts(tc=tc_ts)\n",
    "            self.results.append((name, result.progress))\n",
    "        return self.results\n",
    "\n",
    "    def plot(self, figsize) -> plt.Figure:\n",
    "        results = self.results if self.results != None else self.run()\n",
    "        fig, axs = plt.subplots(len(results), 1, figsize=figsize)\n",
    "        if len(results) == 1:\n",
    "            axs = [axs]\n",
    "\n",
    "        last_axes = []\n",
    "        for ax, (name, progress) in zip(axs, results):\n",
    "            flow_progress = progress.loc[progress[\"type\"] == \"flow\"]\n",
    "            flow_progress[\"edges-added\"] /= 1e6\n",
    "            ax.set(yscale=\"log\", zorder=1)\n",
    "            \n",
    "            ax.plot(\"time\", \"source-sent\", data=flow_progress, label=f\"Source Sent\", alpha=0.85)\n",
    "            ax.plot(\"time\", \"sink-received\", data=flow_progress, linestyle=\"--\", label=f\"Sink Received\")\n",
    "\n",
    "            ymin, ymax = ax.get_ylim()\n",
    "\n",
    "            ax.vlines(progress.loc[progress[\"type\"] == \"query-triggered\"][\"time\"], ymin, ymax, label=f\"Query Triggered\", color=\"purple\", linewidth=1)\n",
    "            ax.vlines(progress.loc[progress[\"type\"] == \"query-done\"][\"time\"], ymin, ymax, linestyle=\"--\", label=f\"Query Answered\", color=\"green\", linewidth=1)\n",
    "            ax.set(xlim=[0, progress.iloc[-1][\"time\"]], ylim=[ymin, ymax])\n",
    "            ax.title.set(text=name, size=10)\n",
    "            ax.patch.set_visible(False)\n",
    "\n",
    "            ax1 = ax.twinx()\n",
    "            ax1.set(zorder=0, ylim=[0, max(flow_progress[\"edges-added\"])])\n",
    "            ax1.fill_between(\"time\", \"edges-added\", data=flow_progress, alpha=0.15, facecolor=\"green\", label=f\"# of Edges Added\")\n",
    "            ax1.locator_params(axis='y', nbins=5)\n",
    "            last_axes = [ax, ax1]\n",
    "\n",
    "            ax.set(frame_on=False)\n",
    "            ax.minorticks_off()\n",
    "            ax1.set(frame_on=False)\n",
    "            ax1.minorticks_off()\n",
    "        \n",
    "        axs[-1].set_xlabel(\"Algorithm Time (ms)\")\n",
    "\n",
    "        handles0, labels0 = last_axes[0].get_legend_handles_labels()\n",
    "        handles1, labels1 = last_axes[1].get_legend_handles_labels()\n",
    "        handles, labels = handles0+handles1, labels0+labels1\n",
    "        fig.legend(handles, labels, bbox_to_anchor=(0.5, 0.98), loc='lower center', ncol=3, prop={'size': 10}, handlelength=3)\n",
    "        fig.text(-0.025, 0.56, \"Flow Amount\", va='center', rotation='vertical')\n",
    "        fig.text(1.01, 0.56, \"Millions of Edges\", va='center', rotation='vertical')\n",
    "        fig.tight_layout(pad=1)\n",
    "        return fig\n",
    "\n",
    "progress_experiment = ProgressExperiment([\n",
    "    (tc_hive_comments[0], f\"Subplot 1: Hive-comments, Most Popular (s,t)\"),\n",
    "    (tc_hive_comments[4], f\"Subplot 2: Hive-comments, 5th Most Popular (s,t)\"),\n",
    "    (tc_wikipedia_growth[0], f\"Subplot 3: Wikipedia-growth, Most Popular (s,t)\")\n",
    "    ], 128)\n",
    "# result = progress_experiment.run()\n",
    "fig = progress_experiment.plot((6,4))\n",
    "fig.savefig(output_dir / \"progress.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scalability(figsize) -> fig:\n",
    "    df = pd.read_csv(results_dir / \"scalability.csv\")\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    x = df.loc[:, \"cores\"]\n",
    "    ax.plot(x, df.loc[:, \"Reference\"] / 1000, \"--\", alpha=0.5, color=\"grey\") # Reference line\n",
    "    ax.plot(x, df.loc[:, \"(C)onstruction Only\"] / 1000, \"x-\", color=\"chocolate\", label=\"(C)onstruction Only\", markersize=5)\n",
    "    ax.plot(x, df.loc[:, \"(S)tatic\"] / 1000, \"D-\", color=\"purple\", label=\"(S)tatic\", markersize=3)\n",
    "    ax.plot(x, df.loc[:, \"(C)+(S)\"] / 1000, \"s-\", color=\"firebrick\", label=\"(C)+(S)\", markersize=3)\n",
    "    ax.plot(x, df.loc[:, \"Dynamic\"] / 1000, \".-\", color=\"royalblue\", label=\"Dynamic\", markersize=5)\n",
    "\n",
    "    xticks, yticks = x.to_list(), [32, 64, 128, 256, 512, 1024]\n",
    "    ax.set_xscale('log', base=2)\n",
    "    ax.set_yscale('log', base=2)\n",
    "    ax.grid(which='major', linestyle='-', linewidth='1', axis=\"y\", alpha=0.5)\n",
    "    ax.set(xticks=xticks, xticklabels=xticks, yticks=yticks, yticklabels=yticks, xlabel=\"Core Count\", ylabel=\"Wall Clock Time (seconds)\")\n",
    "    ax.legend(prop={'size': 7})\n",
    "\n",
    "    ax.set(frame_on=False)\n",
    "    ax.tick_params(bottom=False, left=False) \n",
    "\n",
    "    fig.tight_layout(pad=0.5)\n",
    "    return fig\n",
    "\n",
    "scalability_fig = plot_scalability((5, 2.5))\n",
    "scalability_fig.savefig(output_dir / \"scalability.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowTest():\n",
    "    def __init__(self, testcases: list[BasicTestCase], delete_window: int, query_intervals: list[int]) -> None:\n",
    "        self.delete_window = delete_window\n",
    "        self.query_intervals = query_intervals\n",
    "        self.testcases_ts = [\n",
    "            [\n",
    "                (interval, [\n",
    "                    TimeseriesTestCase(interval_time=interval, **tc.__dict__)\n",
    "                    for tc in tcs\n",
    "                ])\n",
    "                for interval in query_intervals\n",
    "            ]\n",
    "            for tcs in testcases\n",
    "        ]\n",
    "\n",
    "        self.columns_runtime = []\n",
    "        self.columns_latency = []\n",
    "        for i in query_intervals:\n",
    "            self.columns_runtime += [f\"runtime-{i}-a\", f\"runtime-{i}-d\"]\n",
    "        for i in query_intervals:\n",
    "            self.columns_latency += [f\"latency-{i}-a\", f\"latency-{i}-d\"]\n",
    "        self.results = pd.DataFrame(index=[tcs[0].graph.name for tcs in testcases], columns=self.columns_runtime+self.columns_latency)\n",
    "\n",
    "    def run(self) -> pd.DataFrame:\n",
    "        for tc_row in self.testcases_ts:\n",
    "            for interval, tcs in tc_row:\n",
    "                add_termination, add_latency, del_termination, del_latency = [], [], [], []\n",
    "                for tc_add in tcs:\n",
    "                    assert interval == tc_add.interval_time\n",
    "\n",
    "                    tc_del = TimeseriesTestCase(**tc_add.__dict__)\n",
    "                    tc_del.delete_window = self.delete_window\n",
    "\n",
    "                    result_add = run_algorithm_ts(tc=tc_add)\n",
    "                    result_del = run_algorithm_ts(tc=tc_del)\n",
    "\n",
    "                    add_termination.append(result_add.time_termination)\n",
    "                    add_latency.append(result_add.latency_mean)\n",
    "                    del_termination.append(result_del.time_termination)\n",
    "                    del_latency.append(result_del.latency_mean)\n",
    "                print(add_latency)\n",
    "                self.results.at[tc_add.graph.name, f\"runtime-{interval}-a\"] = np.nanmean(add_termination)\n",
    "                self.results.at[tc_add.graph.name, f\"latency-{interval}-a\"] = np.nanmean(add_latency)\n",
    "                self.results.at[tc_del.graph.name, f\"runtime-{interval}-d\"] = np.nanmean(del_termination)\n",
    "                self.results.at[tc_del.graph.name, f\"latency-{interval}-d\"] = np.nanmean(del_latency)\n",
    "        self.results = self.results / 1000 # convert to seconds\n",
    "        return self.results\n",
    "\n",
    "    def save(self) -> None:\n",
    "        results = self.run()\n",
    "\n",
    "        tab_total = \"% Total Runtime\\n\"\n",
    "        df_total = results.loc[:, self.columns_runtime]\n",
    "        tab_total += \"& \" + \" & \".join([c[8:] for c in self.columns_runtime]) + \" \\\\\\\\\\n\"\n",
    "        for index, row in df_total.iterrows():\n",
    "            tab_total += index + \" & \" + \" & \".join([f\"{v:.2f}\" for v in row.values]) + \" \\\\\\\\\\n\"\n",
    "\n",
    "        tab_latency = \"% Average Latency\\n\"\n",
    "        df_latency = results.loc[:, self.columns_latency]\n",
    "        tab_latency += \"& \" + \" & \".join([c[8:] for c in self.columns_latency]) + \" \\\\\\\\\\n\"\n",
    "        for index, row in df_latency.iterrows():\n",
    "            tab_latency += index + \" & \" + \" & \".join([f\"{v:.2f}\" for v in row.values]) + \" \\\\\\\\\\n\"\n",
    "\n",
    "        tab_deletions = tab_total + \"\\n\" + tab_latency\n",
    "        with open(output_dir / \"tab-deletions.txt\", \"w\") as f:\n",
    "            f.write(tab_deletions)\n",
    "\n",
    "n = 10\n",
    "sliding_window = SlidingWindowTest(testcases=[tc_hive_comments[:n], tc_wikipedia_growth[:n], tc_flickr_growth[:n]], delete_window=120, query_intervals=[128, 64, 32])\n",
    "result = sliding_window.run()\n",
    "sliding_window.save()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_ts(dfs: list[pd.DataFrame]) -> pd.DataFrame:\n",
    "    # TODO: Fix this\n",
    "    assert len(dfs) > 0\n",
    "    output_df = pd.DataFrame()\n",
    "    output_df.loc[:, \"Date\"] = pd.to_datetime(output_df.loc[:, \"Date\"])\n",
    "    return output_df\n",
    "\n",
    "class RateLimitingTest():\n",
    "    def __init__(self, testcases: list[BasicTestCase], delete_window: int, query_intervals: list[int], ingest_rates: list[int]) -> None:\n",
    "        self.delete_window = delete_window\n",
    "        self.testcases_basic = testcases\n",
    "        self.query_intervals = query_intervals\n",
    "        self.ingest_rates = ingest_rates\n",
    "        self.testcases_ts = [\n",
    "            [\n",
    "                [\n",
    "                    TimeseriesTestCase(interval_time=interval, delete_window=delete_window, target_ingest_rate=rate, **tc.__dict__)\n",
    "                    for tc in testcases\n",
    "                ]\n",
    "                for rate in ingest_rates\n",
    "            ]\n",
    "            for interval in query_intervals\n",
    "        ]\n",
    "\n",
    "        indices = pd.MultiIndex.from_product([query_intervals, ingest_rates])\n",
    "        columns = [tc.get_name() for tc in testcases] + [\"ingest-rate\", \"latency-average\"]\n",
    "        self.results = pd.DataFrame(index=indices, columns=columns)\n",
    "\n",
    "    def run(self) -> pd.DataFrame:\n",
    "        for testcases_intervals in self.testcases_ts:\n",
    "            for testcases_rates in testcases_intervals:\n",
    "                for tc in testcases_rates:\n",
    "                    result = run_algorithm_ts(tc=tc)\n",
    "                    self.results.at[(tc.interval_time, tc.target_ingest_rate), tc.get_name()] = result\n",
    "                    self.results.at[(tc.interval_time, tc.target_ingest_rate), \"ingest-rate\"] = result.ingest_rate_actual\n",
    "                    self.results.at[(tc.interval_time, tc.target_ingest_rate), \"latency-average\"] = result.latency_mean\n",
    "        return self.results \n",
    "    \n",
    "    def plot_1(self, y_max, x_min, figsize, legend_box) -> plt.Figure:\n",
    "        name = self.testcases_basic[0].name\n",
    "        timeseries = self.results.iloc[0][name].timeseries\n",
    "        timestamps, e = pd.to_datetime(timeseries[\"Date\"]), timeseries[\"EdgeCount\"]\n",
    "        min_ts, max_ts, max_e = min(timestamps), max(timestamps), max(e)\n",
    "        print(f\"min(ts)={min_ts} max(ts)={max_ts} max(e)={max_e}\")\n",
    "        tc_names = [tc.get_name() for tc in self.testcases_basic]\n",
    "\n",
    "        fig, axs = plt.subplots(len(self.query_intervals), len(self.ingest_rates), sharex=True, sharey=True, figsize=figsize)\n",
    "\n",
    "        for row_index, interval in enumerate(self.query_intervals):\n",
    "            for column_index, rate in enumerate(self.ingest_rates):\n",
    "                ax = axs[row_index, column_index]\n",
    "\n",
    "                print(f\"{interval}, {rate}\")\n",
    "                results = self.results.loc[(interval, rate), tc_names].values.tolist()\n",
    "                ts = get_averaged_ts([r.timeseries for r in results])\n",
    "                print(ts)\n",
    "\n",
    "                x, y1 = ts[\"Date\"], ts[\"Latency\"]\n",
    "                # ax.patch.set_visible(False)\n",
    "                # ax.set(xlim=[x_min, max_ts], ylim=[0,y_max], zorder=2, xticks=[])\n",
    "                ax.plot(x, y1, marker = '.', markersize = 5, color=\"chocolate\", label=\"Latency (ms) (left)\")\n",
    "                ax.fill_between(x, y1, alpha=0.2, facecolor=\"red\", edgecolor=None)\n",
    "        \n",
    "        fig.tight_layout(pad=0.5)\n",
    "        return fig\n",
    "    \n",
    "    def plot_2(self, figsize) -> plt.Figure:\n",
    "        fig, axs = plt.subplots(len(self.query_intervals), 1, sharex=True, sharey=True, figsize=figsize)\n",
    "        tc_names = [tc.get_name() for tc in self.testcases_basic]\n",
    "\n",
    "        for row_index, interval in enumerate(self.query_intervals):\n",
    "            ax = axs[row_index]\n",
    "            x, y_mid, y_top, y_bottom = [r / 1e6 for r in self.ingest_rates], [], [], [] # [r / 1e6 for r in self.ingest_rates]\n",
    "            for rate in self.ingest_rates:\n",
    "                results = self.results.loc[(interval, rate), tc_names]\n",
    "                latencies = []\n",
    "                for result in results:\n",
    "                    latencies += result.timeseries.loc[:, \"Latency\"].values.tolist()\n",
    "                # rates = [result.ingest_rate_actual for result in results]\n",
    "                # x.append(statistics.mean(rates) / 1e6)\n",
    "                y_mid.append(statistics.median(latencies) / 1000)\n",
    "                y_top.append(np.percentile(latencies, 80) / 1000)\n",
    "                y_bottom.append(np.percentile(latencies, 20) / 1000)\n",
    "            \n",
    "            \n",
    "            ax.plot(x, y_mid, marker = '.', markersize = 5, color=\"chocolate\", label=\"Latency (ms)\")\n",
    "            ax.fill_between(x, y_bottom, y_top, alpha=0.2)\n",
    "            # ax.set_ylabel(f\"{interval} days\", labelpad=7)\n",
    "            # ax.set_ylabel(f\"Result Latency (seconds)\", labelpad=7)\n",
    "            ax.annotate(f\"Query Interval: {interval} days\", xy=(0.99, 0.96), xycoords='axes fraction', \n",
    "                        horizontalalignment='right', verticalalignment='top', bbox={\"boxstyle\": \"round\", \"color\": \"white\", \"alpha\": 0.7})\n",
    "            ax.set(frame_on=False)\n",
    "            ax.tick_params(bottom=False, left=False)\n",
    "            ax.grid(which='major', linestyle='-', linewidth='1', axis=\"both\", alpha=0.5)\n",
    "        \n",
    "        ax.set(ylim=[-0.1, 3.1])\n",
    "        ax.invert_xaxis()\n",
    "        axs[-1].set_xlabel(f\"Ingestion Rate (million events/second)\", labelpad=7)\n",
    "        fig.text(-0.03, 0.56, \"Result Latency (seconds)\", va='center', rotation='vertical')\n",
    "\n",
    "        fig.tight_layout(pad=0.5)\n",
    "        return fig\n",
    "\n",
    "rate_limiting_test = RateLimitingTest(testcases=tc_hive_comments[:1], delete_window=0, query_intervals=[64, 32], ingest_rates=list(range(300000, 0, -50000))+[25000])\n",
    "# rate_limiting_test = RateLimitingTest(testcases=tc_wikipedia_growth[:1], delete_window=0, query_intervals=[512, 256, 128, 64, 32], ingest_rates=range(5000000, 2000000, -250000))\n",
    "results = rate_limiting_test.run()\n",
    "# fig = rate_limiting_test.plot_1(0, 0, (6, 4), None)\n",
    "fig = rate_limiting_test.plot_2((5, 3))\n",
    "fig.savefig(output_dir / \"rate-limiting.pdf\", bbox_inches='tight')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StabilityTest:\n",
    "    # Note that Line 145 (new = old) breaks this test.\n",
    "    def __init__(self, tc: BasicTestCase, interval_time: int, interval_edge: int) -> None:\n",
    "        self.testcase = TimeseriesTestCase(interval_time=interval_time, interval_edge=interval_edge, **tc.__dict__)\n",
    "        self.count_columns = [\"total-flow-vertex-dynamic\", \"total-flow-vertex-static\", \"same-flow-vertex-dynamic\", \"same-flow-vertex-static\"]\n",
    "        self.percentage_columns = [\"same-percent-dynamic\", \"same-percent-static\"]\n",
    "        self.columns = [\"latency-dynamic\", \"latency-static\"] + self.percentage_columns + self.count_columns\n",
    "        self.count_columns_original = [\"VertexNumInFlowDynamic\", \"VertexNumInFlowStatic\", \"VertexFlowSameDynamic\", \"VertexFlowSameStatic\"]\n",
    "    \n",
    "    def run(self) -> pd.DataFrame:\n",
    "        result_stability = run_algorithm_ts(tc=self.testcase, stability=True)\n",
    "        result_latency = run_algorithm_ts(tc=self.testcase)\n",
    "\n",
    "        index = pd.to_datetime(result_latency.timeseries.loc[:, \"Date\"])\n",
    "        self.result = pd.DataFrame(index=index, columns=self.columns)\n",
    "\n",
    "        self.result.loc[:, \"latency-dynamic\"] = result_latency.timeseries.loc[:, \"Latency\"].values\n",
    "        counts = result_stability.timeseries_flow.tail(self.result.shape[0]).loc[:, self.count_columns_original + [\"StaticLatency\"]].values\n",
    "        self.result.loc[:, self.count_columns + [\"latency-static\"]] = counts\n",
    "        self.result.loc[:, \"same-percent-dynamic\"] = self.result.loc[:, \"same-flow-vertex-dynamic\"] / self.result.loc[:, \"total-flow-vertex-dynamic\"]\n",
    "        self.result.loc[:, \"same-percent-static\"] = self.result.loc[:, \"same-flow-vertex-static\"] / self.result.loc[:, \"total-flow-vertex-static\"]\n",
    "        print(result_latency.ingest_rate_actual)\n",
    "        return self.result\n",
    "\n",
    "    def plot(self, y_min_percentage, y_max_latency, figsize) -> plt.Figure:\n",
    "        result = self.run()\n",
    "        x = result.index[1:]\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax.plot(x, result[\"same-percent-dynamic\"].iloc[1:], marker = 'x', markersize = 6, label=f\"Same Vertices, Dynamic (Left)\")\n",
    "        ax.plot(x, result[\"same-percent-static\"].iloc[1:], marker = '.', markersize = 8, label=f\"Same Vertices, Static (Left)\")\n",
    "\n",
    "        ax.yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "        ax.tick_params(axis='x', labelrotation = 45)\n",
    "        ax.set_xticks(x)\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "        ax.set(xlim=[x[0]-timedelta(days=10), x[-1]+timedelta(days=10)], ylim=[y_min_percentage-0.05, 1.05], zorder=1, yticks=np.arange(0, 1.2, 0.2))\n",
    "        ax.patch.set_visible(False)\n",
    "        ax.xaxis.grid(alpha=0.3)\n",
    "        ax.yaxis.grid(alpha=0.3)\n",
    "        ax.set_xlabel(\"Graph Evolution (Date)\", labelpad=5)\n",
    "        ax.set_ylabel(\"% of Same Vertices\", labelpad=-2)\n",
    "        ax.tick_params(axis='x', which='major', pad=-5)\n",
    "\n",
    "        ax1 = ax.twinx()\n",
    "        ax1.set(ylim=[-0.25, y_max_latency+0.25], ylabel=f\"Result Latency (s)\", zorder=1, yticks=range(6))\n",
    "        ax1.plot(x, result[\"latency-dynamic\"].iloc[1:] / 1000, marker = 'x', markersize = 6, linestyle='dashed', label=f\"Latency, Dynamic (Right)\")\n",
    "        ax1.plot(x, result[\"latency-static\"].iloc[1:] / 1000, marker = '.', markersize = 8, linestyle='dashed', label=f\"Latency, Static (Right)\")\n",
    "\n",
    "        ax.set(frame_on=False)\n",
    "        ax1.set(frame_on=False)\n",
    "        ax.tick_params(bottom=False, right=False, left=False, top=False)\n",
    "        ax1.tick_params(bottom=False, right=False, left=False, top=False)\n",
    "\n",
    "        fig.legend(bbox_to_anchor=(0.51, 0.97), loc='lower center', ncol=2, framealpha=1, prop={'size': 9}, handlelength=3)\n",
    "        fig.tight_layout(pad=0)\n",
    "        return fig\n",
    "\n",
    "stability_test = StabilityTest(tc_wikipedia_growth[0], interval_time=128, interval_edge=None)\n",
    "result = stability_test.run()\n",
    "fig = stability_test.plot(y_min_percentage=0, y_max_latency=5, figsize=(6, 2.5))\n",
    "fig.savefig(output_dir / \"stability.pdf\", bbox_inches='tight')\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2023-sc-poter-oA663jYI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
