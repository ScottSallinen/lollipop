{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for CPEN 534 Course projects\n",
    "\n",
    "This notebook contains the scripts to run all experiments and generate all figures in the poster (and its Extended Abstract).\n",
    "Please follow the these step:\n",
    "1. Run `pipenv install` to install the python dependencies specified in `Pipfile` and `Pipfile.lock`.\n",
    "2. Ensure `go version` is `1.22.1`.\n",
    "3. Update the values of `path_to_graph`, `path_to_project`, and `threads` in the next cell.\n",
    "4. Run all cells in this notebook with the python environment created in Step 1.\n",
    "5. The results will be saved in the directory `results/2024-cpen534/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "project_path = \"/home/juntong/lollipop-partitioning\" # root of the repository\n",
    "path_hive_comments = \"/home/juntong/hive-comments.txt\"\n",
    "path_wikipedia_growth = \"/home/juntong/wikipedia-growth.txt\"\n",
    "path_eth_transfers = \"/home/juntong/eth-transfers.txt\"\n",
    "path_flickr = \"/home/juntong/flickr-growth.txt\"\n",
    "# path_roadnet = \"/home/juntong/roadNet-CA.txt.shuffled\" # shuffled with random edge weights added # ignore this for now\n",
    "\n",
    "default_thread = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re\n",
    "import time\n",
    "import statistics\n",
    "import os, signal\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "go = Path(shutil.which(\"go\"))\n",
    "project_path = Path(project_path).expanduser()\n",
    "path_hive_comments = Path(path_hive_comments).expanduser()\n",
    "path_wikipedia_growth = Path(path_wikipedia_growth).expanduser()\n",
    "path_eth_transfers = Path(path_eth_transfers).expanduser()\n",
    "path_flickr = Path(path_flickr).expanduser()\n",
    "# path_roadnet = Path(path_roadnet).expanduser()\n",
    "assert go.exists()\n",
    "assert project_path.exists()\n",
    "assert path_hive_comments.exists()\n",
    "assert path_wikipedia_growth.exists()\n",
    "assert path_eth_transfers.exists()\n",
    "assert path_flickr.exists()\n",
    "# assert path_roadnet.exists()\n",
    "\n",
    "# TODO: check hashes of graph files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_directory(top_dir: Path):\n",
    "    results_dir = top_dir / f\"2024-cpen534\"\n",
    "    log_dir = results_dir / \"log\"\n",
    "    ts_dir = results_dir / \"ts\"\n",
    "    output_dir = results_dir / \"output\"\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    log_dir.mkdir(exist_ok=True)\n",
    "    ts_dir.mkdir(exist_ok=True)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    return results_dir, output_dir, log_dir, ts_dir\n",
    "\n",
    "(project_path / \"results\").mkdir(exist_ok=True)\n",
    "results_dir, output_dir, log_dir, ts_dir = create_results_directory(project_path / \"results\")\n",
    "path_timeseries_output = project_path / \"results\" / \"push-relabel-timeseries.csv\"\n",
    "path_timeseries_flow_output = project_path / \"results\" / \"push-relabel-timeseries-flow.csv\"\n",
    "path_partitioning_output = project_path / \"results\" / \"partitioning-stats.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(kw_only=True)\n",
    "class Graph:\n",
    "    name: str\n",
    "    path: Path\n",
    "    pw: int\n",
    "    pt: int\n",
    "    undirected: bool = False\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class ExperimentConfig:\n",
    "    graph: Graph\n",
    "    cmd: str\n",
    "    threads: int = default_thread\n",
    "    dynamic: bool = False\n",
    "    target_ingest_rate: int = 0\n",
    "    mla: bool = False\n",
    "    mlaLoad: str = \"v\"\n",
    "    mlaAlpha: float = 0.0\n",
    "    mlaBatch: int = 1\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class BasicTestCase(ExperimentConfig):\n",
    "    threads: int = default_thread\n",
    "\n",
    "graph_hive_comments = Graph(name=\"Hive-comments\", path=path_hive_comments, pw=None, pt=1)\n",
    "graph_wikipedia_growth = Graph(name=\"Wikipedia-growth\", path=path_wikipedia_growth, pw=None, pt=2)\n",
    "graph_eth_transfers = Graph(name=\"Eth-transfers\", path=path_eth_transfers, pw=1, pt=2)\n",
    "graph_flickr_growth = Graph(name=\"Flickr-growth\", path=path_flickr, pw=None, pt=2)\n",
    "# graph_roadnet = Graph(name=\"RoadNet-CA\", path=path_roadnet, pw=1, pt=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(g: Graph, xlog: bool = False):\n",
    "    degrees = dict()\n",
    "    with open(g.path) as file:\n",
    "        for line in file:\n",
    "            src, _ = line.split(maxsplit=1)\n",
    "            if src not in degrees:\n",
    "                degrees[src] = 1\n",
    "            else:\n",
    "                degrees[src] += 1\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
    "    ax.set(title=f'{g.name}', xlabel='Out Degree', ylabel='# of Vertices', yscale='log', xlim=[0, max(degrees.values())])\n",
    "    if xlog:\n",
    "        ax.set(xscale='log')\n",
    "    ax.hist(degrees.values(), bins=100)\n",
    "\n",
    "    fig.tight_layout(pad=0)\n",
    "    fig.savefig(output_dir / f\"degree-histogram-{g.name}.pdf\", bbox_inches='tight')\n",
    "\n",
    "# plot_histogram(graph_wikipedia_growth)\n",
    "# plot_histogram(graph_hive_comments, xlog=False)\n",
    "# plot_histogram(graph_flickr_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Result:\n",
    "    cfg: ExperimentConfig\n",
    "    # time_alg: int\n",
    "    # time_general: int\n",
    "    edge_cuts: int\n",
    "    num_edges: int\n",
    "    df_partitioning: pd.DataFrame\n",
    "    balance_v: float\n",
    "    balance_e: float\n",
    "    balance_msg: float\n",
    "    edge_cut: float\n",
    "    inter_partition_msg: float\n",
    "\n",
    "def get_result(cfg: ExperimentConfig, path_log: Path, partitioning_output: Path) -> Result:\n",
    "    log = path_log.read_text()\n",
    "\n",
    "    # time_alg = re.findall(r\"Termination: ([0-9]+)\", log)\n",
    "    # assert len(time_alg) == 1 \n",
    "    # time_alg = int(time_alg[0])\n",
    "\n",
    "    # time_general = re.findall(r\"Total including streaming: ([0-9]+)\", log)\n",
    "    # assert len(time_general) == 1 \n",
    "    # time_general = int(time_general[0])\n",
    "\n",
    "    edge_cuts = re.findall(r\"Edge Cuts: ([0-9]+)\", log)\n",
    "    assert len(edge_cuts) == 1 \n",
    "    edge_cuts = int(edge_cuts[0])\n",
    "\n",
    "    num_edges = re.findall(r\"Edges: +([0-9]+)\", log)\n",
    "    assert len(num_edges) == 1 \n",
    "    num_edges = int(num_edges[0])\n",
    "\n",
    "    df_partitioning = pd.read_csv(partitioning_output)\n",
    "\n",
    "    assert df_partitioning.loc[:, \"out_edges\"].sum() == num_edges\n",
    "    assert df_partitioning.loc[:, \"in_edges\"].sum() == num_edges\n",
    "\n",
    "    vertices = df_partitioning.loc[:, \"vertices\"].values\n",
    "    edges = df_partitioning.loc[:, \"out_edges\"].values\n",
    "    msgs_all = (df_partitioning.loc[:, \"msg_recv_local\"] + df_partitioning.loc[:, \"msg_recv_remote\"]).values\n",
    "    msgs_remote = df_partitioning.loc[:, \"msg_recv_remote\"].values\n",
    "    balance_v = max(vertices) / (sum(vertices) / len(vertices))\n",
    "    balance_e = max(edges) / (sum(edges) / len(edges))\n",
    "    balance_msg = max(msgs_all) / (sum(msgs_all) / len(msgs_all))\n",
    "    edge_cut = edge_cuts / num_edges\n",
    "    inter_partition_msg = sum(msgs_remote) / sum(msgs_all)\n",
    "\n",
    "    return Result(cfg=cfg, edge_cuts=edge_cuts, num_edges=num_edges, df_partitioning=df_partitioning, balance_v=balance_v, balance_e=balance_e, balance_msg=balance_msg, edge_cut=edge_cut, inter_partition_msg=inter_partition_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(cfg: ExperimentConfig, repeat_index: int = 0, correctness: bool = True, add_flags: list[str] = [], suffix: str = \"\", no_skip: bool = False) -> Path:\n",
    "    # compile command and log filename\n",
    "    cmd = [go, \"run\", project_path / \"cmd\" / f\"lp-{cfg.cmd}\", \"-nc\", f\"-t={cfg.threads}\", f\"-g={cfg.graph.path}\", \"-tg=1\"]\n",
    "    log_filename = f\"{cfg.cmd}-t={cfg.threads}-g={cfg.graph.path.name}\"\n",
    "    if cfg.cmd == \"sssp\":\n",
    "        cmd.append(\"-i=38806\")\n",
    "        log_filename += \"-i=38806\"\n",
    "    if cfg.graph.undirected:\n",
    "        cmd.append(\"-u\")\n",
    "        log_filename += \"-u\"\n",
    "    if cfg.graph.pw:\n",
    "        cmd += [f\"-pw={cfg.graph.pw}\"]\n",
    "        log_filename += f\"-pw={cfg.graph.pw}\"\n",
    "    if cfg.graph.pt:\n",
    "        cmd += [f\"-pt={cfg.graph.pt}\"]\n",
    "        log_filename += f\"-pt={cfg.graph.pt}\"\n",
    "    if cfg.dynamic:\n",
    "        cmd += [f\"-de=100000\"]\n",
    "        log_filename += f\"-de=100000\"\n",
    "    if cfg.target_ingest_rate != 0:\n",
    "        cmd += [f\"-dr={cfg.target_ingest_rate}\"]\n",
    "        log_filename += f\"-dr={cfg.target_ingest_rate}\"\n",
    "    if cfg.mla:\n",
    "        cmd += [f\"-mla\", f\"-ml={cfg.mlaLoad}\", f\"-ma={cfg.mlaAlpha}\", f\"-mb={cfg.mlaBatch}\"]\n",
    "        log_filename += f\"-mla-ml={cfg.mlaLoad}-ma={cfg.mlaAlpha}-mb={cfg.mlaBatch}\"\n",
    "    \n",
    "\n",
    "    if correctness:\n",
    "        cmd += [\"-c\"]\n",
    "        log_filename += \"-c\"\n",
    "\n",
    "    cmd += add_flags\n",
    "    log_filename += \"\".join(add_flags)\n",
    "\n",
    "    log_filename += f\"{suffix}.{repeat_index}.log\"\n",
    "\n",
    "    # Run command\n",
    "    log_path = log_dir / log_filename\n",
    "    print(f\"Command: {cmd}\")\n",
    "    print(f\"Log path: {log_path}\")\n",
    "\n",
    "    if (not no_skip) and log_path.exists():\n",
    "        print(f\"Skipped as the log file exists\")\n",
    "        return log_path\n",
    "\n",
    "    path_log_temp = log_dir / f\"_running-{log_filename}\"\n",
    "    with open(path_log_temp, \"w+t\") as log_file:\n",
    "        def preexec_fn():\n",
    "            os.setpgrp()\n",
    "        process = sp.Popen(cmd, cwd=project_path, stdout=log_file, stderr=sp.STDOUT, preexec_fn=preexec_fn)\n",
    "        time.sleep(0.5)\n",
    "        try:\n",
    "            returncode = process.wait()\n",
    "        except KeyboardInterrupt as ki:\n",
    "            os.killpg(os.getpgid(process.pid), signal.SIGTERM)\n",
    "            process.kill()\n",
    "            raise ki\n",
    "        if returncode != 0:\n",
    "            assert False, f\"Return code is none-zero: {returncode}\"\n",
    "    \n",
    "    path_log_temp.rename(log_path)\n",
    "    print(f\"Log saved\")\n",
    "    \n",
    "    return log_path\n",
    "\n",
    "def run_algorithm_partitioning(cfg: ExperimentConfig, **kwargs):\n",
    "    path_log = run_algorithm(cfg=cfg, **kwargs)\n",
    "\n",
    "    path_partitioning = ts_dir / (path_log.name[:-4] + f\".csv\")\n",
    "    if path_partitioning.exists():\n",
    "        print(f\"Partitioning output already exists: {path_partitioning}\")\n",
    "    else:\n",
    "        assert path_partitioning_output.exists(), \"No partitioning output found\"\n",
    "        path_partitioning_output.rename(path_partitioning)\n",
    "        print(f\"Partitioning output saved to: {path_partitioning}\")\n",
    "\n",
    "    return get_result(cfg=cfg, path_log=path_log, partitioning_output=path_partitioning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashExperiment:\n",
    "    def __init__(self):\n",
    "        self.experiments = [\n",
    "            ExperimentConfig(graph=graph_hive_comments, cmd=\"sssp\", mla=False),\n",
    "            ExperimentConfig(graph=graph_flickr_growth, cmd=\"sssp\", mla=False),\n",
    "            ExperimentConfig(graph=graph_wikipedia_growth, cmd=\"sssp\", mla=False)\n",
    "        ]\n",
    "\n",
    "    def run(self):\n",
    "        self.results = []\n",
    "        for experiment in self.experiments:\n",
    "            result = run_algorithm_partitioning(experiment)\n",
    "            self.results.append([result.cfg.graph.name, result.balance_v, result.balance_e, result.balance_msg, result.edge_cut])\n",
    "        self.df_results = pd.DataFrame(self.results, columns=[\"graph\", \"|V|\", \"|E|\", \"|Msgs|\", \"% of Edge Cut\"])\n",
    "        print(self.df_results)\n",
    "\n",
    "    def plot_balance(self, figsize):\n",
    "        df_balance = pd.DataFrame(self.df_results.loc[:, [\"|V|\", \"|E|\", \"|Msgs|\"]].T)\n",
    "        df_balance.columns = self.df_results.loc[:, \"graph\"].values\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "        df_balance.plot(ax=ax, kind=\"bar\", stacked=False, legend=False, edgecolor=\"black\")\n",
    "        hatches = ['/', '/', '/', 'o', 'o', 'o', 'x', 'x', 'x']\n",
    "        for bar, ha in zip(ax.patches, hatches):\n",
    "            bar.set_hatch(ha)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "        ax.legend(loc='lower center', ncol=4, bbox_to_anchor=(0.5, -0.3))\n",
    "        ax.grid(axis='y')\n",
    "        ax.set(ylim=(0, 3), axisbelow=True, ylabel=\"Load Imbalance\")\n",
    "        \n",
    "        fig.tight_layout(pad=0.5)\n",
    "        return fig\n",
    "\n",
    "    def plot_edge_cut(self, figsize):\n",
    "        df_edgecut = pd.DataFrame(self.df_results.loc[:, [\"% of Edge Cut\"]].T)\n",
    "        df_edgecut.columns = self.df_results.loc[:, \"graph\"].values\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "        df_edgecut.plot(ax=ax, kind=\"bar\", legend=False, edgecolor = \"black\")\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "        ax.grid(axis='y')\n",
    "        ax.set(ylim=(0, 1), axisbelow=True)\n",
    "        ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "        hatches = ['/', 'o', 'x']\n",
    "        for bar, ha in zip(ax.patches, hatches):\n",
    "            bar.set_hatch(ha)\n",
    "        \n",
    "        fig.tight_layout(pad=0.5)\n",
    "        return fig\n",
    "\n",
    "hash_experiment = HashExperiment()\n",
    "hash_experiment.run()\n",
    "height = 3\n",
    "fig_balance = hash_experiment.plot_balance((5.5,height))\n",
    "fig_edgecut = hash_experiment.plot_edge_cut((2,height))\n",
    "fig_balance.savefig(output_dir / \"hash-balance.pdf\", bbox_inches='tight')\n",
    "fig_edgecut.savefig(output_dir / \"hash-edgecut.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadCriteriaExperiment:\n",
    "    def __init__(self):\n",
    "        self.experiments = [\n",
    "            ExperimentConfig(graph=graph_hive_comments, cmd=\"sssp\", mla=False),\n",
    "            ExperimentConfig(graph=graph_hive_comments, cmd=\"sssp\", mla=True, mlaLoad=\"v\"),\n",
    "            ExperimentConfig(graph=graph_hive_comments, cmd=\"sssp\", mla=True, mlaLoad=\"e\"),\n",
    "            ExperimentConfig(graph=graph_hive_comments, cmd=\"sssp\", mla=True, dynamic=True, mlaLoad=\"msg\"),\n",
    "        ]\n",
    "        self.names = [\"Hash\", \"Balancing |V|\", \"Balancing |E|\", \"Balancing #Msgs+0.01|E|\"]\n",
    "\n",
    "    def run(self):\n",
    "        self.results = []\n",
    "        for name, experiment in zip(self.names, self.experiments):\n",
    "            result = run_algorithm_partitioning(experiment)\n",
    "            self.results.append([name, result.balance_v, result.balance_e, result.balance_msg])\n",
    "        self.df_results = pd.DataFrame(self.results, columns=[\"Balancing Criteria\", \"|V| Balance\", \"|E| Balance\", \"#Msgs Balance\"])\n",
    "        self.df_results.set_index(\"Balancing Criteria\", inplace=True)\n",
    "\n",
    "    def plot(self, figsize):\n",
    "        def plot_optimize_criteria(ax, df_full, balance_criteria):\n",
    "            df = pd.DataFrame(df_full.loc[balance_criteria, :]).T\n",
    "            df.plot(ax=ax, kind=\"bar\", stacked=False, legend=False, edgecolor=\"black\")\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.grid(axis='y')\n",
    "            ax.set(ylim=(0, 3), axisbelow=True, title=balance_criteria)\n",
    "            hatches = ['/', 'o', 'x']\n",
    "            for bar, ha in zip(ax.patches, hatches):\n",
    "                bar.set_hatch(ha)\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            fig.legend(handles, labels, loc='lower center', ncols=len(handles), bbox_to_anchor=(0.5, -0.05))\n",
    "\n",
    "        fig, axs = plt.subplots(2, 2, figsize=figsize)\n",
    "        plot_optimize_criteria(axs[0, 0], self.df_results, self.names[0])\n",
    "        plot_optimize_criteria(axs[0, 1], self.df_results, self.names[1])\n",
    "        plot_optimize_criteria(axs[1, 0], self.df_results, self.names[2])\n",
    "        plot_optimize_criteria(axs[1, 1], self.df_results, self.names[3])\n",
    "        axs[0, 0].set(ylabel=\"Load Imbalance\")\n",
    "        axs[1, 0].set(ylabel=\"Load Imbalance\")\n",
    "\n",
    "        fig.tight_layout(pad=0.5)\n",
    "        return fig\n",
    "\n",
    "load_criteria = LoadCriteriaExperiment()\n",
    "load_criteria.run()\n",
    "fig = load_criteria.plot(figsize=(8,5))\n",
    "fig.savefig(output_dir / \"load-criteria.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaExperiment:\n",
    "    def __init__(self, alphas):\n",
    "        self.experiments = []\n",
    "        for alpha in alphas:\n",
    "            self.experiments.append(ExperimentConfig(graph=graph_hive_comments, cmd=\"sssp\", mla=True, mlaAlpha=alpha, mlaLoad=\"e\"))\n",
    "            self.experiments.append(ExperimentConfig(graph=graph_flickr_growth, cmd=\"sssp\", mla=True, mlaAlpha=alpha, mlaLoad=\"v\"))\n",
    "            self.experiments.append(ExperimentConfig(graph=graph_wikipedia_growth, cmd=\"sssp\", mla=True, mlaAlpha=alpha, mlaLoad=\"v\"))\n",
    "\n",
    "    def run(self):\n",
    "        self.results = []\n",
    "        for experiment in self.experiments:\n",
    "            result = run_algorithm_partitioning(experiment)\n",
    "            self.results.append([experiment.graph.name, experiment.mlaLoad, experiment.mlaAlpha, result.edge_cut, result.inter_partition_msg, result.balance_v, result.balance_e, result.balance_msg])\n",
    "        self.df_results = pd.DataFrame(self.results, columns=[\"Graph\", \"Load\", \"Alpha\", \"Edge-Cut\", \"Inter-Partition Msg\", \"|V| Balance\", \"|E| Balance\", \"#Msgs Balance\"])\n",
    "\n",
    "    def plot(self, figsize):\n",
    "        load_criteria_name = {\"v\": \"|V|\", \"e\": \"|E|\", \"msg\": \"#Msg\"}\n",
    "        def plot_ax(ax, graph, load_criteria, xlim, legend):\n",
    "            df = self.df_results[self.df_results[\"Graph\"] == graph]\n",
    "            x = df[\"Edge-Cut\"]*100\n",
    "            ax.plot(x, df[\"|V| Balance\"], '-o', label=\"|V| Balance\")\n",
    "            ax.plot(x, df[\"|E| Balance\"], '-x', label=\"|E| Balance\")\n",
    "            ax.plot(x, df[\"#Msgs Balance\"], '-v', label=\"#Msgs Balance\")\n",
    "            ax.grid()\n",
    "            ax.set(xlim=(xlim, 100), ylim=(0, 13), axisbelow=True, xlabel=\"Edge-Cut (%)\", title=f\"{graph}\")\n",
    "            if legend:\n",
    "                ax.legend()\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize=figsize, sharey=True)\n",
    "        plot_ax(axs[0], \"Hive-comments\", \"e\", 80, False)\n",
    "        plot_ax(axs[1], \"Flickr-growth\", \"v\", 65, False)\n",
    "        plot_ax(axs[2], \"Wikipedia-growth\", \"v\", 80, True)\n",
    "        axs[0].set(ylabel=\"Load Imbalance\")\n",
    "        fig.tight_layout(pad=0.5)\n",
    "        return fig\n",
    "\n",
    "\n",
    "alpha_experiment = AlphaExperiment([0, 1/8, 2/8, 4/8, 1, 2, 4, 8, 12])\n",
    "# alpha_experiment = AlphaExperiment([0, 1, 8, 64, 128])\n",
    "alpha_experiment.run()\n",
    "fig = alpha_experiment.plot((8,3))\n",
    "fig.savefig(output_dir / \"alpha.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchExperiment:\n",
    "    def __init__(self, alphas, batches):\n",
    "        self.experiments = []\n",
    "        self.batches = batches\n",
    "        self.line_styles = [\"-o\", \"-x\", \"-v\", \"-s\", \"-*\"]\n",
    "        assert len(self.line_styles) >= len(self.batches)\n",
    "        for graph in [graph_hive_comments, graph_flickr_growth, graph_wikipedia_growth]:\n",
    "            for b in batches:\n",
    "                for alpha in alphas:\n",
    "                    self.experiments.append(ExperimentConfig(graph=graph, cmd=\"sssp\", mla=True, mlaAlpha=alpha, mlaBatch=int(b)))\n",
    "\n",
    "    def run(self):\n",
    "        self.results = []\n",
    "        for experiment in self.experiments:\n",
    "            result = run_algorithm_partitioning(experiment)\n",
    "            self.results.append([experiment.graph.name, experiment.mlaLoad, experiment.mlaAlpha, experiment.mlaBatch, result.edge_cut, result.inter_partition_msg, result.balance_v, result.balance_e, result.balance_msg])\n",
    "        self.df_results = pd.DataFrame(self.results, columns=[\"Graph\", \"Load\", \"Alpha\", \"Batch\", \"Edge-Cut\", \"Inter-Partition Msg\", \"|V| Balance\", \"|E| Balance\", \"#Msgs Balance\"])\n",
    "\n",
    "    def plot(self, figsize):\n",
    "        def plot_line(df, ax, line_style, batch_size):\n",
    "            batch_size_name = {1: \"$1$\", 1e3: \"$10^3$\", 1e4: \"$10^4$\", 1e5: \"$10^5$\", 1e6: \"$10^6$\"}[batch_size]\n",
    "            df = df[df[\"Batch\"] == batch_size]\n",
    "            x = df[\"Edge-Cut\"]*100\n",
    "            ax.plot(x, df[\"|V| Balance\"], line_style, label=f\"Batch of {batch_size_name}\")\n",
    "        def plot_graph(df, graph, ax, xlim, ylim):\n",
    "            df = df[df[\"Graph\"] == graph]\n",
    "            for batch, style in zip(self.batches, self.line_styles):\n",
    "                plot_line(df, ax, style, batch)\n",
    "            ax.grid()\n",
    "            ax.set(xlim=(xlim, 100), ylim=(0, ylim), axisbelow=True, xlabel=\"Edge-Cut (%)\", ylabel=\"Load Imbalance\", title=graph)\n",
    "\n",
    "        df = self.df_results\n",
    "        fig, axs = plt.subplots(1, 3, figsize=figsize)\n",
    "        plot_graph(df, \"Hive-comments\", axs[0], 15, 17.5)\n",
    "        plot_graph(df, \"Flickr-growth\", axs[1], 20, 9)\n",
    "        plot_graph(df, \"Wikipedia-growth\", axs[2], 40, 15)\n",
    "        handles, labels = axs[2].get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, loc='lower center', ncols=len(handles), bbox_to_anchor=(0.5, -0.11))\n",
    "        fig.tight_layout(pad=0.5)\n",
    "        return fig\n",
    "        \n",
    "\n",
    "batch_experiment = BatchExperiment([0, 1/8, 2/8, 4/8, 1, 2, 4, 8], [1, 1e3, 1e4, 1e5, 1e6])\n",
    "batch_experiment.run()\n",
    "fig = batch_experiment.plot((9*0.9,3*0.9))\n",
    "fig.savefig(output_dir / \"batch.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2024-cpen534-IRnhN-DM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
