{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Computation Time and Solution Stability on Dynamic Graphs\n",
    "\n",
    "This notebook contains the code to run all experiments and generate all figures in the poster (and its Extended Abstract). Please update the values of the variables below before running the code. The results will be saved in the directory `results/2023-sc-poster/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_graph, timestamp_position = \"~/wikipedia-growth.txt\", 2\n",
    "path_to_project = \"~/projects/lollipop\" # root of the repository\n",
    "threads = 10 # 0 to use nproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas matplotlib\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latency\n",
    "timeseries_intervals = [32, 64, 128] # for the latency graph, in days\n",
    "ingest_rates = [10_000_000, 8_000_000, 6_000_000, 4_000_000, 2_000_000] # events / second. Use 0 to indicate unlimited rate\n",
    "repeat = 10\n",
    "\n",
    "# Stability\n",
    "stability_interval = 800_000 # for the stability experiment\n",
    "\n",
    "path_to_go = shutil.which(\"go\")\n",
    "path_to_graph = Path(path_to_graph).expanduser()\n",
    "path_to_project = Path(path_to_project).expanduser()\n",
    "assert(path_to_graph.exists())\n",
    "assert(path_to_project.exists())\n",
    "assert(path_to_go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_directory():\n",
    "    results_dir = path_to_project / \"results\" / f\"2023-sc-poster\"\n",
    "    log_dir = results_dir / \"log\"\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    log_dir.mkdir(exist_ok=True)\n",
    "    return results_dir, log_dir\n",
    "\n",
    "(path_to_project / \"results\").mkdir(exist_ok=True)\n",
    "results_dir, log_dir = create_results_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Algorithm:\n",
    "    def __init__(self, name: str, graph: Path, log_dir: Path, timeseries_output: Path, timestamp_position: int = 0, convert_to_undirected: bool = False, threads: int = 0, additional_flags: list[str] = []) -> None:\n",
    "        self.name = name\n",
    "        self.code_path = path_to_project / \"cmd\" / f\"lp-{name}\"\n",
    "        self.log_dir = log_dir\n",
    "        self.convert_to_undirected = convert_to_undirected\n",
    "        self.graph = graph\n",
    "        self.timestamp_position = timestamp_position\n",
    "        self.threads = threads\n",
    "        self.timeseries_output = timeseries_output\n",
    "        self.additional_flags = additional_flags\n",
    "        assert(self.graph.exists())\n",
    "        assert(self.log_dir.exists())\n",
    "        assert(self.code_path.exists())\n",
    "        assert(self.timeseries_output.parent.exists())\n",
    "\n",
    "    def run_timeseries(self, timeseries_interval: int, ingest_rate: int = 0, suffix: str = \"\", no_skip: bool = False, additional_flags: list[str] = [], interval_type: str = \"timestamp\", check_correctness: bool = True) -> Path:\n",
    "        path_timeseries = self.log_dir / f\"timeseries-{self.name}-{timeseries_interval}-{ingest_rate}-{self.threads}{suffix}.csv\"\n",
    "        if (not no_skip) and path_timeseries.exists():\n",
    "            print(f\"Skipping as result exists: {path_timeseries}\")\n",
    "            return path_timeseries\n",
    "\n",
    "        cmd = [path_to_go, \"run\", self.code_path, f\"-g={self.graph}\", \"-tquery\"]\n",
    "        if interval_type == \"timestamp\":\n",
    "            cmd.append(f\"-dt={timeseries_interval}\")\n",
    "        elif interval_type == \"edgecount\":\n",
    "            cmd.append(f\"-de={timeseries_interval}\")\n",
    "        else:\n",
    "            assert(False)\n",
    "        if ingest_rate:\n",
    "            cmd.append(f\"-dr={ingest_rate}\")\n",
    "        if self.timestamp_position:\n",
    "            cmd.append(f\"-pt={self.timestamp_position}\")\n",
    "        if self.convert_to_undirected:\n",
    "            cmd.append(\"-u\")\n",
    "        if self.threads:\n",
    "            cmd.append(f\"-t={self.threads}\")\n",
    "        if check_correctness:\n",
    "            cmd.append(f\"-c\")\n",
    "        cmd = cmd + self.additional_flags + additional_flags\n",
    "        \n",
    "        print(f\"Command: {cmd}\")\n",
    "        self.timeseries_output.unlink(missing_ok=True)\n",
    "        process = subprocess.Popen(cmd, cwd=path_to_project)\n",
    "        returncode = process.wait()\n",
    "        assert(returncode == 0)\n",
    "\n",
    "        assert(self.timeseries_output.exists())\n",
    "        return self.timeseries_output.rename(path_timeseries)\n",
    "    \n",
    "pagerank = Algorithm(name=\"pagerank\", graph=path_to_graph, log_dir=log_dir, \n",
    "                     timeseries_output=path_to_project / \"results\" / \"timeseries.csv\", \n",
    "                     timestamp_position=timestamp_position, \n",
    "                     convert_to_undirected=False, threads=threads)\n",
    "\n",
    "colouring = Algorithm(name=\"colouring\", graph=path_to_graph, log_dir=log_dir, \n",
    "                     timeseries_output=path_to_project / \"results\" / \"colouring-timeseries.csv\", \n",
    "                     timestamp_position=timestamp_position, \n",
    "                     convert_to_undirected=True, threads=threads)\n",
    "\n",
    "colouring_oracle = Algorithm(name=\"colouring\", graph=path_to_graph, log_dir=log_dir, \n",
    "                     timeseries_output=path_to_project / \"results\" / \"colouring-snapshot-timeseries.csv\", \n",
    "                     timestamp_position=timestamp_position, additional_flags=[\"-o\"],\n",
    "                     convert_to_undirected=True, threads=threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatencyExperiment:\n",
    "    def __init__(self, log_dir: Path, algorithm: Algorithm) -> None:\n",
    "        self.algorithm = algorithm\n",
    "        self.log_dir = log_dir\n",
    "        self.results_db = pd.DataFrame(columns=[\"Algorithm\", \"Query Interval\", \"Number of Queries\", \"Ingest Rate\", \"Average Latency\", \"Threads\", \"Timeseries Path\"])\n",
    "        assert(self.log_dir.exists())\n",
    "\n",
    "    def run(self, timeseries_intervals: list[int], ingest_rates: list[int], repeat: int=1) -> pd.DataFrame:\n",
    "        for interval in timeseries_intervals:\n",
    "            for rate in ingest_rates:\n",
    "                for r in range(repeat):\n",
    "                    timeseries = self.algorithm.run_timeseries(timeseries_interval=interval, ingest_rate=rate, suffix=f\"-{r}\")\n",
    "                    df_timeseries = pd.read_csv(timeseries)\n",
    "                    average_latency = df_timeseries.loc[:, 'qLatencyMS'].mean()\n",
    "                    self.results_db.loc[len(self.results_db)] = {\n",
    "                        \"Algorithm\": self.algorithm.name,\n",
    "                        \"Query Interval\": interval,\n",
    "                        \"Number of Queries\": df_timeseries.shape[0],\n",
    "                        \"Ingest Rate\": rate,\n",
    "                        \"Average Latency\": average_latency,\n",
    "                        \"Threads\": self.algorithm.threads,\n",
    "                        \"Timeseries Path\": timeseries\n",
    "                    }\n",
    "        return self.results_db\n",
    "\n",
    "colouring_experiment = LatencyExperiment(log_dir, colouring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colouring_results = colouring_experiment.run(timeseries_intervals, ingest_rates, repeat=repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_latency(timeseries_paths: list[str]) -> pd.DataFrame:\n",
    "    assert(timeseries_paths.shape[0] > 0)\n",
    "    output_df = pd.read_csv(timeseries_paths.iloc[0])\n",
    "    output_df = output_df[['ts', 'qLatencyMS']].copy()\n",
    "\n",
    "    for path in timeseries_paths[1:]:\n",
    "        df = pd.read_csv(path)\n",
    "        assert((df['ts'] == output_df['ts']).all())\n",
    "        output_df['qLatencyMS'] = output_df['qLatencyMS'].add(df['qLatencyMS'], fill_value=0)\n",
    "    \n",
    "    output_df['ts'] = pd.to_datetime(output_df['ts'])\n",
    "    output_df['qLatencyMS'] = output_df['qLatencyMS'] / len(timeseries_paths)\n",
    "    return output_df\n",
    "\n",
    "def plot_latency(timeseries_results, y_max, x_min, figsize, legend_box):\n",
    "    timeseries_path = timeseries_results.query(f'`Query Interval` == {min(timeseries_intervals)}').iloc[0][\"Timeseries Path\"]\n",
    "    df_timeseries = pd.read_csv(timeseries_path)\n",
    "    ts, e = pd.to_datetime(df_timeseries['ts']), df_timeseries['EC']\n",
    "    min_ts, max_ts, max_e = min(ts), max(ts), max(e)\n",
    "    print(f\"min(ts)={min_ts} max(ts)={max_ts} e={e}\")\n",
    "    \n",
    "    fig, axs = plt.subplots(len(timeseries_intervals), len(ingest_rates), sharex=True, figsize=figsize)\n",
    "\n",
    "    for interval, axs_y in zip(timeseries_intervals, axs):\n",
    "        for rate, ax in zip(ingest_rates, axs_y):\n",
    "            timeseries_filtered = timeseries_results.query(f'`Query Interval` == {interval} and `Ingest Rate` == {rate} and `Threads` == {threads}')\n",
    "            \n",
    "            # Latency\n",
    "            df_averaged = get_average_latency(timeseries_filtered[\"Timeseries Path\"])\n",
    "            x, y1 = df_averaged['ts'], df_averaged['qLatencyMS']\n",
    "            ax.patch.set_visible(False)\n",
    "            ax.set(xlim=[x_min, max_ts], ylim=[0,y_max], zorder=2, xticks=[])\n",
    "            ax.plot(x, y1, marker = '.', markersize = 5, color=\"chocolate\", label=\"Latency (ms) (left)\")\n",
    "            ax.fill_between(x, y1, alpha=0.2, facecolor=\"red\", edgecolor=None)\n",
    "\n",
    "            if rate != ingest_rates[0]:\n",
    "                ax.set_yticks([])\n",
    "            \n",
    "            # % of edges added\n",
    "            ax = ax.twinx()\n",
    "            ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "            ax.set(ylim=[0,1], zorder=1)\n",
    "            ax.fill_between(ts, e / max_e, alpha=0.2, facecolor=\"green\", edgecolor=None, label=f\"% of edges added (right)\")\n",
    "            if rate != ingest_rates[-1]:\n",
    "                ax.set_yticks([])\n",
    "\n",
    "            # Target rate not achieved.\n",
    "            if rate == ingest_rates[0] or (rate == ingest_rates[1] and interval <= 32): # TODO: automate this\n",
    "                ax = ax.twinx().twiny() # don't share any axes\n",
    "                ax.set(xlim=[0,1], ylim=[0,1], zorder=0, xticks=[], yticks=[])\n",
    "                ax.scatter(0.2, 0.85, marker=\"x\", color=\"brown\", s=100, label=\"Target rate not achieved\")\n",
    "\n",
    "    for interval, ax in zip(timeseries_intervals, axs[:, 0]):\n",
    "        ax.set_ylabel(f\"{interval} days\", labelpad=7)\n",
    "    for rate, ax in zip(ingest_rates, axs[-1]):\n",
    "        ax.set_xlabel(f\"{rate/1e6}m e/s\", labelpad=7)\n",
    "    \n",
    "    # Legend\n",
    "    handles, labels = [sum(x, []) for x in zip(*[ax.get_legend_handles_labels() for ax in fig.axes])]\n",
    "    handles_labels = dict(zip(labels, handles))\n",
    "    fig.legend(handles_labels.values(), handles_labels.keys(), framealpha=0.9,bbox_to_anchor=legend_box)\n",
    "    \n",
    "    fig.tight_layout(pad=0.5)\n",
    "    return fig\n",
    "\n",
    "fig_abstract = plot_latency(colouring_results, 1000, pd.to_datetime(\"2005-03-15\"), (6, 4), (1, 1))\n",
    "fig_poster = plot_latency(colouring_results, 1000, pd.to_datetime(\"2005-03-15\"), (6, 4), (1.4, 1))\n",
    "fig_abstract.savefig(results_dir / \"rate-limiting-abstract.pdf\")\n",
    "fig_poster.savefig(results_dir / \"rate-limiting-poster.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_stability_all_dynamic = colouring_oracle.run_timeseries(timeseries_interval=stability_interval, suffix=f\"-stability-dynamic\", interval_type=\"edgecount\")\n",
    "ts_stability_all_async = colouring_oracle.run_timeseries(timeseries_interval=stability_interval, suffix=f\"-stability-async\", interval_type=\"edgecount\", additional_flags=[\"-SnapshotOracle\"])\n",
    "ts_stability_all_async_wc = colouring_oracle.run_timeseries(timeseries_interval=stability_interval, suffix=f\"-stability-async_wc\", interval_type=\"edgecount\", additional_flags=[\"-SnapshotOracle\", \"-WaitCount\"], check_correctness=False)\n",
    "df_ts_stability_all_dynamic = pd.read_csv(ts_stability_all_dynamic)\n",
    "df_ts_stability_all_async = pd.read_csv(ts_stability_all_async)\n",
    "df_ts_stability_all_async_wc = pd.read_csv(ts_stability_all_async_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stability_percentage(data: list[tuple[pd.DataFrame, str]], y_max: int, figsize):\n",
    "    x = df_ts_stability_all_dynamic[\"EC\"] / 1000000\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    for df, label in data:\n",
    "        ax.plot(x, df[\"pctSame\"], marker = '.', markersize = 5, label=f\"{label} (%)\")\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(100))\n",
    "    ax.tick_params(axis='x', labelrotation = 90)\n",
    "    ax.xaxis.set_major_locator(mtick.MultipleLocator(base=3.2))\n",
    "    ax.set(xlim=[x[1], max(x)], ylim=[0, y_max], ylabel=f\"% of Vertex Colours Unchanged\", zorder=1)\n",
    "    ax.patch.set_visible(False)\n",
    "    ax.xaxis.grid(alpha=0.3)\n",
    "    ax.yaxis.grid(alpha=0.3)\n",
    "    ax.set_xlabel(\"Edge Count (millions)\", labelpad=7)\n",
    "\n",
    "    ax = ax.twinx()\n",
    "    ax.set(zorder=0, ylim=[0, y_max], ylabel=f\"# of Colours Used\")\n",
    "    for df, label in data:\n",
    "        ax.fill_between(x, df[\"colourCount\"], label=f\"{label} (#)\", alpha=0.6)\n",
    "\n",
    "    fig.legend(bbox_to_anchor=(0.51, 1.03), loc='center', ncol=3, framealpha=1, prop={'size': 7.5})\n",
    "    fig.tight_layout(pad=0.5)\n",
    "    return fig\n",
    "\n",
    "fig_poster = plot_stability_percentage([(df_ts_stability_all_dynamic, \"Dynamic\"), (df_ts_stability_all_async, \"Static\"), (df_ts_stability_all_async_wc, \"Static (Wait Count)\")], 100, (6, 3))\n",
    "fig_abstract = plot_stability_percentage([(df_ts_stability_all_dynamic, \"Dynamic\"), (df_ts_stability_all_async, \"Static\"), (df_ts_stability_all_async_wc, \"Static (Wait Count)\")], 100, (9, 3))\n",
    "fig_poster.savefig(results_dir / \"stability-all-vertices-poster.pdf\", bbox_inches='tight')\n",
    "fig_abstract.savefig(results_dir / \"stability-all-vertices-abstract.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_stability_interest_dynamic = colouring_oracle.run_timeseries(timeseries_interval=stability_interval, suffix=f\"-stability-dynamic-interest\", interval_type=\"edgecount\", additional_flags=[\"-UseInterest\"])\n",
    "ts_stability_interest_async = colouring_oracle.run_timeseries(timeseries_interval=stability_interval, suffix=f\"-stability-async-interest\", interval_type=\"edgecount\", additional_flags=[\"-UseInterest\", \"-SnapshotOracle\"])\n",
    "ts_stability_interest_async_wc = colouring_oracle.run_timeseries(timeseries_interval=stability_interval, suffix=f\"-stability-async_wc-interest\", interval_type=\"edgecount\", additional_flags=[\"-UseInterest\", \"-SnapshotOracle\", \"-WaitCount\"], check_correctness=False)\n",
    "df_ts_stability_interest_dynamic = pd.read_csv(ts_stability_interest_dynamic)\n",
    "df_ts_stability_interest_async = pd.read_csv(ts_stability_interest_async)\n",
    "df_ts_stability_interest_async_wc = pd.read_csv(ts_stability_interest_async_wc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_colours_of_vertices(df_list: list[pd.DataFrame], titles: list[str], figsize, y_max):\n",
    "    x = df_list[0][\"EC\"] / 1000000\n",
    "    fig, axes = plt.subplots(1, len(df_list), sharex=True, sharey=True, figsize=figsize)\n",
    "    max_colour_line = 1\n",
    "\n",
    "    for df, title, ax in zip(df_list, titles, axes):\n",
    "        vertices = df.columns[df.columns.get_loc(\"EC\")+2:-1]\n",
    "        max_y = 0\n",
    "        for v in vertices:\n",
    "            y = df[v]\n",
    "            ax.plot(x, y, alpha=0.8, linewidth=1)\n",
    "            max_y = max(max_y, max(y)) # max(max(y), max_y) doesn't work??\n",
    "        ax.set(xlabel=\"Edge Count (millions)\")\n",
    "        ax.title.set_text(title)\n",
    "        ax.yaxis.set_major_locator(mtick.MultipleLocator(10))\n",
    "        ax.yaxis.set_minor_locator(mtick.AutoMinorLocator(10))\n",
    "        ax.yaxis.grid(alpha=0.3, which='minor')\n",
    "        ax.yaxis.grid(alpha=1, which='major')\n",
    "        max_colour_line = ax.plot([x[0], x[len(x)-1]], [max_y, max_y], alpha=1, linewidth=1, color=\"chocolate\")\n",
    "        ax.annotate(f\"{max_y}\", (x[2], max_y+1))\n",
    "\n",
    "    axes[0].set(xlim=[x[0], x[len(x)-1]], ylim=[0, y_max], xlabel=\"Edge Count (millions)\", ylabel=f\"Colour ID\")\n",
    "    fig.legend(max_colour_line, [\"Maximum # of Colours Used\"], bbox_to_anchor=(0.995, 0.95), loc='upper right')\n",
    "    fig.tight_layout(pad=0.5)\n",
    "    return fig\n",
    "\n",
    "fig = plot_colours_of_vertices([df_ts_stability_interest_dynamic, df_ts_stability_interest_async, df_ts_stability_interest_async_wc], [\"Dynamic\", \"Static\", \"Static (Wait Count)\"], (11, 5), 100)\n",
    "fig.savefig(results_dir / \"stability-interest-colours.pdf\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
